<!DOCTYPE html>
<html lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

    <!-- Custom CSS tyle Sheet link -->
    <link href="../style.css" type="text/css" rel="stylesheet">

    <!-- Title -->
    <title>Vivian's Blog</title>
  </head>

  <body>
    <div id="mySidebar" class="sidebar">
      <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
      <a href="../index.html">Home</a></li>
      <a href="./gamified.html">Gamified Task Manager</a></li>
      <a href="./fidelity.html">Fidelity</a></li>
      <a href="./greencrew.html">Sustainable Claremont</a></li>
      <a href="../about.html">Info</a>
    </div>

    <div id="main">
      <button class="openbtn" onclick="openNav()">&#9776;</button>
      
      <!-- Project Header -->
      <div class="proj-header">
        <div class="proj-title">
            <h1>Fidelity Internship</h1>
        </div>
        <div class="proj-dates">
          <p>June-August 2020</p>
      </div>

        <div class="proj-status">
            <p>STATUS: Complete</p>
        </div>
      </div>

        <!-- shortcuts to top and bottom -->
        <div class="proj-shortcuts">
            <div class="proj-shortcuts-top">
                <p><a href="#August-21-2020-FI">&uArr;<br>To newest</a></p>
            </div>
            <div class="proj-shortcuts-bot">
                <p><a href="#June-08-2020-FI">To oldest<br>&dArr;</a></p>
            </div>
        </div>

        <!-- Blog posts -->
        <div class="posts">
          <div id= "August-21-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 21, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Last Day</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  For most of today, I completed more LinkedIn Learning courses and took care of some logistical things for the end of the internship. On LinkedIn learning I completed some courses on source control. Source control doesn't directly relate to my project, since it was largely independent, but I feel that these topics will be useful in the future for more team-based projects.
                </p>
                <p>
                  This afternoon I had the final wrap-up meeting with David, Kiran, Anuj, and Janice. I brought up the remaining open issues and what I have attempted or considered and what is still yet to be done. Kiran updated me on what next steps are being taken with this project. I also got to provide some feedback on this internship with what I enjoyed what could be improved. It seems like the project’s current state is all set for the hand-off, so it was a good last meeting to have, and I feel good about where I left the project.
                </p>
                <p>
                  Overall, I had a great time during my internship at Fidelity this summer. Despite the virtual setting, I’ve had the opportunity to learn a lot of new skills ranging from technical to corporate workflow to connecting with new people. Throughout the whole project, I’ve been excited to see new ways I could expand my project and share my progress. I also had great support from mentors, teammates, and others for project, career, and academic advice and I hope to keep in touch with these connections. I’m excited to see what opportunities next summer holds, but that’s all for now!
                </p>
            </div>
          </div>

          <div id= "August-20-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 20, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Bi-Monthly Meeting</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I had my presentation at the Bi-monthly meeting. This was the largest audience that I’ve presented to this summer (~30 people), but since I’ve given the same presentation quite a few times, I wasn’t too nervous and I think the presentation went pretty well. This morning, I also read over my updated documentation and sent it out to everyone that will be present at tomorrow’s wrap-up meeting. These were the last two big things for my summer internship. The remaining meetings I have are more casual and so far I haven’t gotten any major questions or suggestions on my documentation.
                </p>
                <p>
                  This morning I also had my networking meeting with Renbin. He had a few questions for me about my project since our projects are both about Machine Learning, and I also asked a few questions about his projects. One of his projects is about recognizing toxic comments, which also uses NLP. It’s a bit unfortunate that I wasn’t able to meet him until this late in the internship, since it would’ve been cool to discuss some of the machine learning and NLP concepts I was using with him during the project, share resources, and ask for his insight
                </p>
                <p>
                  This afternoon I learned about project management and more career development on LinkedIn Learning.  I also had the celebration meeting with Laurena, Bob, Angela, Brian, and a few new people. It was nice to meet some new people and talk about topics not directly related to work. Tomorrow I plan to do more LinkedIn learning and have the final wrap-up meeting in the afternoon.
                </p>
            </div>
          </div>

          <div id= "August-19-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 19, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Learning Day</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning, I had my last meeting with Derick. We caught up a bit on what has been happening over the last 3 weeks. I also gave my learning day presentation to him for some feedback and as a practice runthrough. Additionally, I asked Derick about his experience with getting an MBA and how he feels it has contributed to his career path. He talked about the experience of working full time while getting an MBA and mentioned that it was pretty manageable. Additionally, he gave some great advice about how an MBA might not be directly applicable immediately, but in the long run it will be useful for career development and landing the right role. Getting an MBA after working in industry for at least a few years is definitely a career path that I am considering, so this advice was really helpful. Knowing that getting an MBA while working is doable and keeping in mind that even if an MBA might not seem useful right after completing the program it will end up helping my career growth is encouraging for pursuing that path and I definitely plan to look into this path more.
                </p>
                <p>
                  This morning I also had my meeting with Rajiv. I got some answers for some logistics for the end of the internship, reviewed my resume with him, and confirmed that I will be presenting in tomorrow’s bi-monthly meeting. Rajiv suggested that I use the same presentation as I used for my FPAIT presentation, which includes slides about Agile and networking that aren’t directly related to my project. This presentation is about 15 minutes long and since it's so similar to the presentations that I’ve been practicing, I feel pretty prepared for this presentation already.
                </p>
                <p>
                  In the early afternoon, I practiced my presentation for the BSA forum (rescheduled learning day from yesterday). The audience for this presentation was Business System Analysts, so it was a bit of a different audience than I am used to. A few people mentioned how my project has similar applications to projects that they are working on. It was interesting to see how what I worked on this summer is similar to what is going on in other areas of the organization. Angela and Brian from yesterday afternoon’s meeting were also there and Laurena gave her presentation before me, so it was nice to see some familiar faces. After the meeting, Angela invited me to a celebration meeting taking place tomorrow afternoon for the end of our internship period. I’m looking forward to getting to know Angela and Brian better as well as meeting some new people on Laurena’s team. :) 
                </p>
                <p>
                  For the rest of the day I worked on my documentation and added some quick changes to my existing FPAIT presentation in preparation for tomorrow’s bi-monthly meeting presentation. For my documentation, I added a section that explains the current logic, set-up, and shortcomings behind my manual rules proof of concept. I also updated the document control and open issues section. Additionally, I ran through my bi-monthly meeting presentation just to make sure that my slides and script were up to date and properly synchronized.
                </p>
                <p>
                  Tomorrow I have my presentation for the bi-monthly meeting and I plan to send out my updated documentation in the morning after I read it over for errors one more time. I also have a networking meeting with Renbin, who is another intern under CTG, and I have the celebration meeting that Angela invited me to for the end of the internship. In my downtime I plan to spend some time on LinkedIn learning and perhaps complete a course on project management, since talking to Ramya last week has raised my interest in this career path.
                </p>
            </div>
          </div>

          <div id= "August-18-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 18, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Cloud Native and IoT</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent my morning practicing my presentation for the learning day, but unfortunately the learning day had to be rescheduled due to training day running over time. Laurena thinks we might be presenting at the BSA forum tomorrow instead, but we haven’t received any confirmation. Hopefully we can present this week, since Friday is the last day for both Laurena and I. This morning I also updated my resume so that Rajiv can review it tomorrow. I just want to make sure that I am accurately representing what I worked on this summer and make sure I’m not including any confidential information when describing my internship experience on my resume. We rescheduled our 1:1 for tomorrow, since the original 1:1 meeting would have conflicted with the learning day presentation.
                </p>
                <p>
                  For the rest of the day, I completed more LinkedIn learning courses. I completed the course on Cloud Native and its 12 factors that I saw yesterday. Some of this information was a bit too advanced for me to understand, but through the course I got a better idea of what cloud computing is and its approach to building applications. I also completed a course on IoT (Internet of Things), where I learned what IoT is, its applications, and its basic components. This made me realize where IoT is already integrated into my everyday life (like in home security) and its potential for expansion into other industries. This afternoon, I also had my meeting with part of another FPAIT team to discuss next steps for handing off my project after I leave for the summer. I met Bob, Angela, and Brian, all of whom work on Laurena’s team. They have more experience with machine learning, so we discussed more technical topics and potential improvements. These were much more technical questions than I have gotten before, so it brought up some topics that I had considered before, but wasn’t sure how to approach as well as entirely new topics for improvement that I hadn’t considered previously.
                </p>
                <p>
                  Tomorrow, I have my 1:1 with Rajiv where I plan to ask him about my resume, end of internship logistics, and whether or not I am presenting at Thursday’s bi-monthly meeting. Tomorrow I also have my final meeting with Derick now that he is back from his vacation. I’m excited to share my project with him and catch up before my internship ends.
                </p>
            </div>
          </div>
          
          <div id= "August-17-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 17, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Architecture and Public Speaking</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Like Friday, I mainly watched LinkedIn Learning videos throughout my day. I started off with completing a course about the foundations of software architecture. This is an area that I’ve heard about offhand throughout my time at Fidelity, but I wasn't really sure what software architecture actually was, so I thought LinkedIn Learning would provide me with a good introduction to this field. I learned about the role of software architects and how this role has changed as organizations move from waterfall to agile. In waterfall, software architects were removed from developers and would come up with elaborate upfront plans for developers to implement. This approach ran into problems because of approval bottlenecks between developers and architects, out-of-date plans, and inflexible/inefficient workflow. In agile, software architects work closely with the team to come up with plans, help the whole team understand the architecture design, and allows developers to make architectural decisions. This change allows for a more efficient workflow system and more flexible changes as problems arise. I also learned about some of the design processes and categories of architecture like system vs. enterprise architecture. Lastly, I learned about some of the broad concepts of architecture patterns and their pros and cons. The course covered the rather outdated system of monoliths and the way this can cause issues down the line, brief coverage of microkernel/plugins, message-based, reactive and choreographed systems, and microservices. Microservices seemed interesting so I did some additional online learning through some brief online articles. I’d be interested in learning more about software architecture, so I might see if I can find opportunities for next summers relating to this field.
                </p>
                <p>
                  I also watched a few courses today about public speaking skills. I first watched a course about designing a presentation, which had some helpful information that can apply to future presentations as well as the remaining presentations I have this week. I also watched a course on public speaking that had some helpful takeaways, but is more geared towards in-person presentations, so they won’t be directly applicable this summer. Lastly, I completed a course on projecting intelligence to come across as more confident in school and in work. I’ve gotten a lot of experience presenting my project and speaking to new people this summer and I’ve learned a lot on my own from these experiences, but I thought these courses could help point out additional details that I hadn't thought of.
                </p>
                <p>
                  In the afternoon, I also briefly reviewed my script and my presentation in preparation for tomorrow’s learning day presentation. This presentation is pretty similar to the presentation I gave two weeks ago for the FPAIT senior leadership team, so I don’t need to rehearse as much as did for the first time. I still plan to run through the presentation once or twice tomorrow morning before the presentation. Laurena will also be presenting at the learning day tomorrow, so it'll be nice to have a familiar face. I have my meeting with Rajiv tomorrow as well where I plan to ask about a few logistics regarding the end of this internship and recommendations for opportunities next year. I also plan to ask him about whether or not I’m presenting at Thursday’s bi-monthly meeting. For tomorrow afternoon, I plan to complete more LinkedIn Learning courses. The software architecture course today mentioned a course about Cloud Native, so I might check out that course tomorrow. I also found a course about the Internet of Things (IoT), which is another field that I’ve heard a lot about, but haven’t really explored.
                </p>
            </div>
          </div>

          <div id= "August-14-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 14, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Cloud Computing</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I spent my day watching LinkedIn Learning videos. I completed the cloud computing course, where I learned about how cloud services allow for better reliability than traditional data centers since cloud providers specialize in cloud security. Cloud is also more scalable since you can quickly upsize or downsize to adjust  based on what you need. I also thought it was interesting to hear about the different types of cloud solutions and what they are used for. I learned how Saas (Software as a service) is used for providing applications to individuals’ machines (ex: Dropbox, GSuite, WebEx), Paas (Platform as a service) is for giving a whole framework where developers can build software and customized applications (ex: AWS Elastic Beanstalk, Windows Azure, Google App Engine), and Iaas (Infrastructure as a service) works as a full self-servicing for storage, networking, and accessing/monitoring computers so that you can buy resources on demand instead of purchasing hardware (ex: AWS, Microsoft Azure, Google Compute Engine). I also completed a course about developing a professional image, which gave advice on how to transition from college to the workforce. Lastly, I started a course on cybersecurity, which I will finish on Monday. Next week, I plan to continue going through LinkedIn Learning videos. I’d like to take advantage of these resources before my internship ends. I’ll likely spend Monday afternoon and Tuesday morning preparing for the learning day, and I have a few casual meetings from Wednesday through Friday about my project, but I don’t think I need to spend time preparing anything extra for these. I’m not sure if Janice would still like me to present at Thursday's bi-weekly meeting, but if she does, I plan to re-use my presentation from Tuesday’s learning day.
                </p>
            </div>
          </div>

          <div id= "August-13-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 13, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Meeting Interns</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning, I worked on my slides for next Tuesday’s learning day. I mostly just rearranged the slides from the FPAIT presentation last week so the presentation would be more like 10 minutes. I also changed some of the content, since I’ve made progress on my project since last Tuesday with writing directly to the database table. Additionally, I condensed my demonstration to take up less time. I’ll start practicing the slides on Monday to make sure I’m within the 10 minute time frame.
                </p>
                <p>
                  In the afternoon, I completed the new virtual orientation for the extended internship period, which was a little tedious, since it was similar to the information given in intern orientation from a few months ago. This afternoon, I also had a casual meeting with Ben and Alex like last week. Rennah joined for a few minutes and maybe I’ll set up a meeting for next week to talk to her more. Ben, Alex, and I just talked about school, our project process, and computer science topics. Tomorrow is Ben and Alex’s last day, but I’ve added them on LinkedIn, so hopefully we can stay in touch.
                </p>
                <p>
                  I don’t have much planned for tomorrow, so I’ll probably do some LinkedIn Learning. There are some courses on cybersecurity, software architecture, and cloud computing that I plan to get through tomorrow and next week. These are all topics that I don’t know much about, so these courses should be a good introduction to see if I’m interested in exploring these topics more.
                </p>
            </div>
          </div>
          
          <div id= "August-12-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 12, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>CTG Presentation</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  After this morning’s scrum call, I met with Ramya to talk about her role and her responsibilities. I learned a lot about the responsibilities that come with being a scrum master, a product manager, and a business systems administrator. Ramya’s position comes with a lot of responsibilities relating to planning and making sure everything is running smoothly. I thought it was interesting how varied her day-to-day can be between meetings, planning, solving issues, and contacting different people. She also provided a lot of insight about the benefits of Agile and how it keeps a team on track and accountable for the work they are doing. Most notable to me was that she started on a similar academic path as the one I am on! She started as a CS major undergraduate and got a masters in CS, but then based on her experience and the open roles at Fidelity, she ended up taking on different roles with managing projects and being the middleman between developers and the business side. Ramya mentioned how her background in CS is helpful for being able to scope out whether or not a business ask is feasible or not right off the back. I don’t have any experience with project management, but it’s definitely a career path that I’ve started considering this summer and that I would be interested in exploring more.
                </p>
                <p>
                  After my meeting with Ramya, I had a meeting with David, Mallikjurna, Rajiv, and Daniel about my documentation and the remaining issues. It seems like my documentation is in a pretty good place right now. I just need to add a section outlining the steps needed if the business side would like to add more description fields to the model. I sent out my documentation to everyone that was invited to the meeting, so if there is additional feedback, I’ll be on the lookout for emails with suggestions. I brought up the current open issues and it seems like they’re all pretty low priority. I’ll look into adding the manual rules in the form of a table if I have time, but Rajiv and David mentioned that focusing on my upcoming Learning Day presentation and editing documentation will take priority. I set up a wrap-up meeting for next Friday afternoon just to do the final handoff of my project and address any final questions.
                </p>
                <p>
                  I also had my end-of-internship presentation to CTG leadership today. I spent about an hour before my presentation tweaking the script and practicing the presentation. I think my presentation went pretty well, although it was a bit rushed, since I was the last person to present and we were running low on time. It was really interesting to hear about other interns’ presentations as well. Some interns were working with Machine Learning like I was, some worked with data science, some worked with cybersecurity, and some worked with more UI design. It was interesting to see the variety of projects even within the same CTG business unit. After the meeting, one of the interns, Renbin, reached out to me and set up a meeting for next Thursday to talk about our projects.
                </p>
                <p>
                  I also got a few miscellaneous tasks done today. The first was asking about the details of the Learning Day next Tuesday. I messaged Todd, who is the organizer, and asked about what was expected for this presentation. He mentioned that the presentation should be about 10 minutes long, so I’ll use the same presentation as I used for the FPAIT presentation, but I’ll cut out the about Agile and networking. I plan to ask Laurena about her plans to present so we are on the same page about the time slot. I also got a meeting invite to talk about next steps for my NLP Spend tool from Angela, who is on a different team within FPAIT. This meeting is set up for next Tuesday and I’m not exactly sure what to expect, but I’m excited to share my tool with more people and hear about next steps for what I’ve worked on this summer. Lastly, Benjamin is trying to set up a casual meeting with some of the interns. Hopefully we’ll be able to meet on Thursday or Friday, but it seems like a lot of people’s schedules overlap.
                </p>
                <p>
                  Tomorrow, I don’t have any meetings set up on my calendar. I plan to work on my slides for Tuesday’s learning day presentation and check in with Laurena and the length of her presentation. I’ll also keep a look out for any emails regarding suggestions for editing my documentation. If I have downtime, I plan to complete some LinkedIn Learning courses that I started a while ago about cybersecurity, systems architecture, and professional development. I’m hoping to take it easy for the next week as I wrap up.
                </p>
            </div>
          </div>

          <div id= "August-11-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 11, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>More Documentation</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning, I finished writing up my documentation. I finished the appendix and added a link to the presentation that I used for my FPAIT presentation as well as a script that’s used to print some example correlations. I also went through the sections that I wrote yesterday and fixed some formatting and wording. I had my 1:1 with Rajiv, where he gave me some initial feedback about adding my base code files and moving some information to the appendix. After our meeting, I made these quick changes. I’m happy with my draft and I think that my documentation is ready to be reviewed for tomorrow!
                </p>
                <p>
                  This afternoon I had my meeting with Laurena. I had a great time talking to her about school, her project, and her experience with Fidelity. She’s presenting at tomorrow’s end-of-internship meeting and at next Tuesday’s learning day, so it’ll be nice to see a familiar face during these presentations! 
                </p>
                <p>
                  For most of the afternoon I worked on editing the script for tomorrow’s end-of-internship presentation to CTG senior leadership. I changed some information because I’ve made progress on the project since the last time I worked on the presentation. I also cut out a decent amount of information to fit my presentation within the 5-7 minute time slot. Tomorrow, I plan to practice running through my presentation a few more times before presenting to CTG senior leadership in the afternoon. I also have my networking meeting with Ramya, which I’m looking forward to since I’m curious about the responsibilities that come with being a Scrum master. Lastly, I have the meeting to get feedback on my documentation and raise open issues tomorrow with David, Mallikjurna, Rajiv, and Daniel.
                </p>
            </div>
          </div>

          <div id= "August-10-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 10, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Documentation Draft</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent today writing up the draft for my documentation. I have a few questions about what to include or what not to include that I will raise in Wednesday’s documentation review meeting. There are also a few remaining open issues about the structure of the table for manual rules and about database access that I plan to bring up on Wednesday as well. Documentation isn’t my favorite part of projects, but it’s a good way to look back on your code with a critical eye. There were definitely a few times where I needed to clean up my code or add comments to make sure it would be ready for someone else to use. My documentation includes a section for the introduction, which details the purpose and background of the tool, required infrastructure, which details what users need to download in order to use the tool, a flowchart, which details the high-level steps of how the tool works, a step-by-step guide for running the scripts, which includes setting up the user’s environment as well as what users should expect when they run their scripts, and an appendix. The appendix is the section that I’m least sure about. I’ve included details about the algorithms and complex functions that the model uses, but I’m not sure if I’ve included too much or little information. Tomorrow I plan to continue working on my documentation. I still need to finish up the appendix section and I plan to review the section I wrote today. I have my 1:1 with Rajiv tomorrow, so I’m hoping he can take a look at the documentation I have and give me some advice before Wednesday’s meeting. I also have my networking meeting with Laurena tomorrow, which I’m looking forward to since it seems like we have similar presentations coming up and it’ll be nice to have a friend. :)
                </p>
            </div>
          </div>

          <div id= "August-07-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 7, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Successfully Writing To Oracle!</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I was able to get the method for writing to Oracle working at a much more reasonable runtime. :) This morning I ran my program (with Toad closed) and it took about 20 minutes to complete 118k rows. I messaged Rajiv about my progress and he mentioned that he had a method that would help with the efficiency. He used an Oracle query to set a unique index so that the cost of running the query would be lower and the program would be more efficient. After adding a unique identifier, the runtime for solely writing to Oracle went down to less than a minute! I added this to my existing code, and it takes about 4-5 minutes total to run the predictions and write to Oracle, which is comparable to the runtime when I was writing to Excel. At this point I’m pretty much finished with my tool!
                </p>
                <p>
                  Rajiv mentioned that the next steps for my project are mainly to get documentation down and make sure others can set up my tool. He sent over a template to be used for documentation which I’ll be using for my documentation. My documentation will include an overview of my project’s purpose/problem statement, the flowchart I made a few weeks ago, required infrastructure, and how to use the tool. I might add some additional appendix items about the algorithms I used and the presentation I gave on Tuesday since they might be helpful for future users or developers. I started working on the documentation’s formatting today and I updated my flowchart to include the database requirements. Next week, I’ll continue filling out the content of this guide. I set up a meeting with Kiran, David, Rajiv, and Daniel for next Wednesday so that we can review the documentation and address any remaining issues, like the format of the table that will hold manual rules.
                </p>
                <p>
                  Today I set up some networking opportunities, which I’m looking forward to. I set up a meeting with Ramya, our team’s Scrum Master for Monday. I’m hoping to ask her about her career path and her role as a Systems Analyst as well as her experience as a Scrum master. I also set up a meeting with Laurena, a fellow intern under FPAIT. She mentioned that she’s a double major, so I’m curious about how her project plays into both her majors and getting her general opinion of Fidelity. Lastly, I met up with Ben and Alex, a member of the groupchat Ben added me to yesterday. There were a few other interns in the groupchat that couldn’t make it today, but hopefully we’ll get to meet next week. We talked about our projects, our teams, and our schools. It’s nice to continue meeting new people this far into the internship and I hope to keep in contact even after the internship ends.
                </p>
                <p>
                  I also got an invite to present at a learning day in 2 weeks. I’ll be giving the same presentation as I gave to the FPAIT leadership team on Tuesday, but this time to a different audience. I haven’t participated in a learning day before, so I’m not sure what to expect, but I might ask Laurena since I know she’ll also be presenting on this learning day and she might have a better idea of what’s expected from the presenters, especially if she’s attended learning days before.
                </p>
                <p>
                  Next week, I’ll be mostly focusing on getting my documentation together before my meeting on Wednesday. I also have my presentation for CTG’s senior team on Wednesday, so I’ll spend some time polishing my script and practicing the presentation to fit within the time limits. After presenting to FPAIT’s leadership on Tuesday, I’m feeling less nervous about this presentation. I’m also looking forward to my networking meetings next week and getting to know some new people!
                </p>
            </div>
          </div>

          <div id= "August-06-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 6, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Technically a Technology Associate</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I spent another day trying to write to the database table. Yesterday’s method was much too slow, so I tried another approach. I found a source that used a different Python to Oracle function that takes care of the problem of looping through the dataframe at the same time as you write to the database table row by row. I had to make some adjustments to my code to get this method to work. First, I formatted my dataframes into tuples since this method can only take in one list of tuples. Then I struggled for a while with converting types, since in the database table one of the fields is stored as a ‘NUMBER’ but python numpy.int64 or numpy.int32 types are not compatible with the Oracle ‘NUMBER’. Eventually, I just used list comprehension to convert to a Python native int within my sql query. I’m not sure if this method is the most efficient, but it seems to work for now. I can work on optimization later.
                </p>
                <p>
                  Then, I tried running the program in Python, but it was taking a really long time to connect to the database and an even longer time to execute the command. I even tried reducing the number of rows being written to Oracle to only include 100 rows. I let this run for about an hour, but when it still hadn’t finished executing I felt it was reasonable to assume that something was fundamentally wrong, not that my code was just slow, especially since I was able to write the same data to Excel within a minute. I tried to use online resources to troubleshoot and see where the issue might be coming from, but could not find anything that fit my situation. Eventually, as a last ditch effort, I closed my connection on Toad and ran the program again. The program was able to execute in reasonable time for 100 rows! It’s still quite slow to run on all 100k+ rows and wasn’t able to finish executing by the end of the day, since I only found the solution with closing Toad before running the Python program at the very end of the work day, but I’ll definitely try running my program again tomorrow morning to see if it works.
                </p>
                <p>
                  In my downtime while I was waiting for my code to run, I got involved with a few other tasks. First was that Benjamin added me to a small group chat with other interns whose internship periods were being extended. This was nice, especially since the internship webinars are no longer being held. I also filled out some paperwork for the extended period. For the next 2 weeks, I’m technically a ‘Technology Associate’ which is fun :). Being added to a new internship group has inspired me to reach out and try networking with new people. I might reach out to Laurena who is in FPAIT and gave her presentation before me on Tuesday, since she mentioned that her internship period was also being extended. I might also reach out to Ramya and ask her about her work and her role as a Systems Administrator since I’m not too familiar with this role and I’m interested in her experience being a Scrum Master.
                </p>
            </div>
          </div>

          <div id= "August-05-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 5, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>cx_Oracle Struggles continued…</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent the entirety of my day continuing to try writing to the database table. I used some of the methods I researched yesterday. As a test, I tried updating the table so all the columns have the same value using cx_Oracle and the query command Rajiv showed me yesterday. I was able to run this without the database, value, and type errors I was getting yesterday and updated the table successfully, which is a good sign. However, the more challenging task is to update the table row by row using the predicted values which are stored in a pandas dataframe. I can’t find an efficient way to set a whole column in the database equal to a whole column of my python dataframe. I researched many different methods, and it seems like the only feasible way is to create an intermediary temporary table and transfer data from the temporary table to the final table. However, this might not be a sustainable way to complete the task and might create excess loose ends in the database structure. Additionally, I don’t have the correct permissions to do this, so it’s out of the question for now. The approach I’m taking is by looping through my dataframe and updating the database table row-by-row. This method is very slow, but I’d like to see if it works. If this method works, then I can work on making it more efficient and altering my approach. Otherwise, I might need to ask for more database permissions again so that I can try the approach of creating a new temporary database table for my predictions, transferring the columns from this temporary table to the final table, and then deleting the temporary table. But getting permissions to create and delete tables could be challenging, so I’m trying to avoid this if possible. Tomorrow, I’ll keep trying to find an efficient way to write from Python to the database.
                </p>
            </div>
          </div>

          <div id= "August-04-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 4, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>FPAIT Presentation</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I gave my presentation to the FPAIT leadership group and I think it went pretty well! Following my prepared script definitely helped me stay on track and helped me avoid stumbling over my words. :)  Laurena, the other intern who presented, gave a really interesting presentation about her project which is more front-facing and concerned with the business side of things.
                </p>
                <p>
                  Later, I had my 1:1 meeting with Rajiv. I updated him on what we talked about in last Thursday’s meeting with the business procurement team. I mentioned that the manual rules were suggested to be implemented in a table, but since I’m not familiar with database architecture, I’m not sure how the table would be set up. He suggested that we could meet with Kiran to discuss the design of the manual rules table so I know what to implement. I also brought up my struggles with writing my results directly to the table. Kiran mentioned that this wasn’t the highest priority on Thursday, but I would like to get it figured out since I feel that it would help the usability of my tool. Rajiv showed me some Oracle commands that I could use to update the table as desired. It turns out that I was inserting into the bottom of the table instead of updating the existing columns with my old methods. He also found an online resource that was more Python-oriented. Using this new advice and new Oracle commands, I can resume working on writing to the database table instead of writing to Excel.
                </p>
                <p>
                  I spent most of my afternoon starting on my script that writes directly to the database table. I mostly looked into online resources for advice on how to set up and approach this using an Oracle query so that I could use the query that Rajiv showed me during our 1:1. I tried a few of the approaches that I found using online resources, but I’m still resolving database errors, value errors, and incorrect type errors. I think I might need to adjust some of the structures throughout the prediction phase of my existing code to resolve these. I’ll keep testing and trying different approaches tomorrow.
                </p>
                <p>
                  After the meeting with Janice and Rajiv yesterday about my presentation, Janice had some great suggestions about what to include in my 5-7 minute end-of-internship presentation, so I made some adjustments to my slides and scripts. The main thing I worked on was adjusting my demonstration to be included in my slides instead of having to exit out of the presentation to show my spreadsheet. I also emphasized the points about specific takeaways I had from my project, since Janice mentioned that this would be what the senior leadership is most interested in. 
                </p>
                <p>
                  I had my 1:1 with Nancy today as well, so it was nice to catch up with her and what she’s working on. Tomorrow I don’t have any meetings scheduled, so I’ll spend my day continuing to try to write to the database. Since the formal internship period is almost over, there aren’t any more webinar events. This means from now on I’ll be focusing more and more on my personal projects. I might set up time with people on my team or on other teams to network so that I have some breaks in my day.
                </p>
            </div>
          </div>

          <div id= "August-03-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>AUGUST 3, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Altered Presentation</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning, after the scrum meeting, I got in touch with Kiran about getting access to more database tables. David sent me the query that he used to to pull data from the database into the spreadsheet on Thursday. I forwarded this to Kiran so he could see which tables I need access to. He mentioned that he would work with DBA to get my access added. For now, I’ll keep working with the imported spreadsheet. I also thought a little about the format of the manual rules table. The information I need in the table is the category the rule is applied to, the key that triggers the rule application, and the manual override values for each of the three categories. A simple design would be to just have a standalone 5 column table with these fields, but I’m not super familiar with database design, so there might be another system using key values that is more efficient. I plan to ask Rajiv about his thoughts tomorrow. For now, since I’m not sure what the format of the table will look like, I’m holding off on actually implementing a method to read in rules from the table.
                </p>
                <p>
                  Early in the afternoon, there was an email about the agenda for tomorrow’s FPAIT senior leadership meeting, which stated that I have a 20 minute slot during the meeting to give my presentation. I contacted the other intern who was presenting in this meeting, who said that she planned to give a 15 minute presentation. I also double checked with Rajiv who agreed that I should expand my presentation to be longer. My original plan was to give the same 5-7 minute end-of-internship presentation to the FPAIT team, but since I was given a larger time slot that I originally anticipated, I decided I could take this opportunity to explain more of the details of my project. I spent the afternoon working on adding back some of the slides that I originally moved to the appendix and writing up a script for these newly added slides. I ran through the presentation a few times to make sure my presentation was around 15 minutes. At the end of the day, I had a meeting with Rajiv and Janice about my presentation, where they gave me some feedback on information to add or certain aspects to highlight from my presentation. Janice also gave some great suggestions on what parts of this longer presentation I should include in my presentation to Tammy and the CTG leadership team for my end-of-internship presentation next week.
                </p>
                <p>
                  The presentation is tomorrow morning, so I’ll probably spend the hour or so before the presentation practicing and making sure my demo is in working order. I also have my 1:1 meeting with Rajiv tomorrow, so I’ll bring up the problem I’m running into with writing to the database via Python and ask about next steps with implementing the manual rules.
                </p>
            </div>
          </div>

          <div id= "July-31-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 31, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Polishing Presentations</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today was a pretty relaxed day, since the only meeting I had was Power To Wow in the afternoon. I spent most of my day working on my end-of-internship presentation. I’m having a hard time getting my presentation within the time limit. I think the best approach will be to perfect my script so that I can speak more quickly throughout the presentation and I don't waste time stumbling over my words. I cut out some parts of my demo. I think I can get away with cutting out these parts since they include more specific information than might be necessary, but I’ll see what Rajiv and Janice think of this on Monday. For now, I’m still a bit over time, so I might ask Janice and Rajiv for suggestions on where to cut out information.
                </p>
                <p>
                  Today I also started thinking about the manual rules implementation. Even if I don’t get access to the database within the next few days, I might be able to practice the formatting using a pandas dataframe, since cx_Oracle reads tables from databases into dataframes. However, I’m reluctant to get started on this until I get confirmation on what form the table will be implemented in since I don’t want to have to overwrite previous work if there is a last-minute change of mind on the formatting. The general structure for implementing manual rules in place, so the piece that’s left is just the format that the manual rules will come in. I tried to create a sample manual rules table in Oracle, but I don’t have the right permissions. Since Kiran said he’s changing database permissions currently, I’ll reach out to him in a few days if I still don’t see my permissions changing.
                </p>
                <p>
                  This afternoon, I had the Power To Wow presentation with Nancy, Benjamin, Gabe, Anushka, and Jenna. I practiced my Power To Wow presentation a little bit this morning and I think my presentation went pretty well. It definitely wasn’t as polished as my end-of-internship presentation, but given that this is more of a public-speaking exercise than a presentation I think it’s appropriate that this presentation was more informal. Jenna presented about her project, which was concerned with UI design. It was interesting to hear about different types of projects that people are working on. Nancy presented about grocery bagging, which has a lot more nuance than I expected. This exercise will hopefully help me with thinking on the spot, like answering questions in presentations.
                </p>
                <p>
                  Next week, I’ll try and work on implementing manual rules using data tables or at least using pandas dataframes if I can’t get access to the database. I’ll also be presenting to Janice on Monday and to Karin on Tuesday. Once I get feedback, I can improve and change my presentation before I present to Tammy and CTG leadership on August 12th. I’m not sure what else to work on for my tool, so maybe I’ll ask Rajiv if he has suggestions if I get stuck with manual rules or if I’m happy with my presentation.
                </p>
            </div>
          </div>
          
          <div id= "July-30-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 10, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Manual Rules Meeting</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I got the implementation of reading from Oracle and writing to Excel working with my manual rules. Since I already had the separate components of reading data from Oracle, writing formatted outputs to Excel, and applying manual rules working I just had to combine them in the right order and make sure everything was consistent. The run time is a little but slower than the previous version without manual rules and without the database connection. It takes about 2 minutes to save the model and 4-5 minutes to run the predictions. For now, I’m ok with this efficiency, but once I get access to more data, I’ll need to observe how my model scales and make changes accordingly.
                </p>
                <p>
                  At noon I had my meeting with Kiran, Anuj, David, and Chris from Business Procurement. I updated them on my accuracy and efficiency for getting the predictions for different levels of commodity codes and on adding manual rules. It seems like the commodity code predictions are on track. David gave me some insight on the places where my code’s predictions don’t match the expected values. In some cases my predictions might be right even if they don’t match the expected value and in other cases I’ll need to go back and make some adjustments. I also showed them my approaches to implementing manual rules using the rigid for-loop structure and using the more broad dictionary/stopword structure. It seems like the rigid for-loop structure is more in line with what Dave Diamond (Head of Procurement Analytics and Programs) is looking for. Kiran suggested that the implementation in the future will likely be a table with the values that map to certain commodity codes. Once I get more clarity on what this table might look like and get more access to creating test tables in the database, I’ll work on transitioning my current model to this structure. David also suggested a more flexible approach of using NLP within the rules so that it doesn’t rely on such specific rules and can be more adaptable. I’ll look into more flexible rules using NLP, since I think it’s an interesting approach and would avoid the mess of manual rules, if I have time but for now I will stick with Dave Diamond’s ask for rigid manual rules. Kiran also gave some updates about the database. The meeting was extended but Kiran and Anuj had to leave, so I talked to Chris and David a bit more about my tool. David is using NLP in his project, so I offered to share the same folder that I shared with the India development team last week with him. Additionally, David offered to share the Oracle query he used to pull the data from the database into the spreadsheet he sent me a few weeks ago so that when I get access to the database I can recreate the same data format as I have been using, which will prove to be very useful given my lack of experience in Oracle. Overall, this meeting was really productive and I have a better understanding of the direction I should be going in.
                </p>
                <p>
                  I also brought up my struggles with writing to the database and Kiran said that writing results to the database isn’t of the highest priority, so for now I’ll work more on manual rules implementation and fine-tuning my model. I’ll come back to writing to the database table if I can get some permissions fixed when Kiran has time. Since I don’t have to worry too much about writing to the database for now, I uploaded the files for defining my manual rules, saving models using the database table, and predicting into and excel. I also updated my quick guide to include descriptions of these files and a few additional steps to run these files. This way my folder is up-to-date and David has access to the files I showed in my presentation instead of outdated files from before I started working with the database.
                </p>
                <p>
                  I spent a little bit of time practicing my Power To Wow presentation and my presentation script, but I think I’ll need to practice more tomorrow. I set up a meeting with Janice for Monday to get some initial feedback on my presentation before I present to Karin on Tuesday. I definitely need to cut down on my script. Rajiv recommended that I add a slide to summarize what I’ve learned throughout the project in terms of tools and skills. This slide puts me over the time limit, but since it's an important slide I can probably accommodate for it by cutting out information in other places. I’ll work on this tomorrow.
                </p>
                <p>
                  Tomorrow, I plan to practice my end-of-internship presentation and my Power To Wow presentation. The Power To Wow event is tomorrow afternoon, so I’m excited to see what everyone else has prepared. Tomorrow, I’ll also think about what an implementation for reading manual rules from a table might look like, but since I don’t have the correct permissions, I won’t be able to actually implement it yet. I also plan to also analyze some of the mismatched predictions from my tool.
                </p>
            </div>
          </div>
          
          <div id= "July-29-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 29, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>More Presentation Prep and cx_Oracle</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning after the daily scrum call, I saw that Fidelity Central had some additional videos about updates in Personal Investing and Workplace Investing. I spent some time watching these videos to catch up on Fidelity news and get an idea of what was going on in these business units. The videos were primarily concerning how Fidelity has been adjusting to the Covid-19 environment. I think it's nice that they update company-wide on what is going on in different business units to feel more connected with the whole company especially when working virtually.
                </p>
                <p>
                  I spent the rest of the morning working on my Power To Wow slides. Since this presentation is just for fun, it was a nice break to be able to focus my attention toward something other than my main project. I might add some speaker notes tomorrow since the Power To Wow meeting got pushed to Friday, but I don’t plan to write out a whole script so that I can practice presenting on the spot.
                </p>
                <p>
                  I spent the afternoon continuing trying to write my predictions from my Python dataframe to the database table, but I am still having no luck. Hopefully tomorrow’s meeting will clear things up with accessing the database, or I will have the opportunity to ask if others have suggestions on how to write to database table columns using Python. Otherwise, I might just stick to reading information from the database but writing the results into an Excel spreadsheet as I have been. This midway compromise will allow me to access the large amount of data stored in the database table and does not run the risk of me editing the information in the table. I’ll ask the others if this is an acceptable solution.
                </p>
                <p>
                  I also spent some time today editing the script for my end-of-internship presentation based on the suggestions that Rajiv gave me yesterday. I’m not sure if Rajiv still wants to set up a meeting with Janice for this week, but I’ll be prepared if he wants to set up a meeting for tomorrow or Monday. Otherwise, I’ll be prepared ahead of time for my presentation for Karin and her senior staff team next Tuesday.
                </p>
                <p>
                  I didn’t have any meetings today, so I was able to focus on working on my presentations and trying to write to the database table. Tomorrow there’s a webinar about Women in Cloud Webinar which I’m looking forward to. I don’t know much about cloud, so this should be a good opportunity to learn about a new technology field. My meeting with Kiran and the Business Procurement about connecting to the database is also tomorrow, so hopefully I can get some clarity about writing to the database table or if writing to Excel is acceptable. I’ll reach out to Rajiv if I'm still stuck after the meeting. If I have time, I plan to practice the updated presentation script and run through my Power To Wow presentation.
                </p>
            </div>
          </div>

          <div id= "July-28-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 28, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Presentation Formatting and cx_Oracle Challenges</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I finished importing the data. Since the spreadsheet had 235k rows, it took quite a while. Not all the data was transferred because of an incorrectly labeled field on my end. However, this table is primarily for me to practice pulling data from the database and printing the results to the same database table, so it is good enough for this purpose. I added the 3 necessary columns for predictions once the data was finished importing. I’m able to read in data from the database table but I haven’t figured out how to write to the database table. I haven’t been able to find any online resources that show examples of writing pandas dataframes to specific columns in a database table. Most resources have information on writing a dataframe to a new table or appending rows to the bottom of a table. I’ll keep looking into this tomorrow, but if it is not possible, then I will read in from the database then write to an Excel spreadsheet.
                </p>
                <p>
                  Today I also met with Rajiv. I updated him on how I have finished implementations for writing manual rules. He had some ideas for how the Business side might also implement rules using their own tables, but since I have no way of knowing what they will actually choose to implement, it seems like my current status with manual rules is good enough. I also informed him of my database setup where I upload an Excel sheet into a table instead of using an existing table. He mentioned that he would reach out to Kiran about getting access to more data from the database instead of from the same table as I have been using. Lastly, I showed him my presentation slides.  He sent me a Fidelity template for me to transfer the information in my original slides into so that it is aligned with a format that the senior leadership is used to. However, I wasn’t satisfied with the layout of the template since it's meant for a monthly report and not a general overview. I felt that the slide template was too information-dense for an overview slide deck. It might be hard for others to follow my points if I pack each slide with that much information since they are not familiar with my project. I spent most of my day transferring my slides into the template and changing the formatting. While I was at it, I changed by bi-monthly meeting project demo slides to the template format as well. I sent the edited slide deck to Rajiv when I finished and by the end of the day, Rajiv was able to give me his feedback and it seems like there’s nothing for me to change at the moment. He suggested that we meet with Janice before I meet with Karin, but it seems like both of their schedules are pretty packed, so I’m not sure how likely this is to happen. On the note of presentations, I decided on a Power To Wow topic this afternoon as well. Power To Wow is the public speaking exercise that Nancy set up for Thursday. I chose TikToks since it's something I’m interested in and can talk about pretty easily. In contrast to my end-of-internship presentation and my project demo presentation, I want to try not to prepare a word-for-word script so I can practice more on-the-spot public speaking.
                </p>
                <p>
                  Tomorrow I will work on creating myPower To Wow slides and continue troubleshooting my issues with writing new columns into the database table. Kiran arranged a meeting for Thursday with some members of the Business Procurement Team to discuss connecting to a database. Rajiv is taking Friday off so I’ll try and reach out to him by Thursday if I continue having issues with the database.
                </p>
            </div>
          </div>
                
          <div id= "July-27-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 27, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Creating Tables</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I worked on importing information from the table David originally gave me to a new Oracle database. The table that I was given access last week to did not have all the fields that I was originally using to train my model and make predictions. I asked Kiran about the missing fields and he advised me to just import the existing data to Oracle and analyze from there. My model will be working at the same scale as it has been since the data is exactly the same but it will be writing to Oracle instead of Excel. I was looking forward to working with more data to see how my model’s accuracy and efficiency scales, but for now this will be good for making the transition from Excel to Oracle. However, I ran into some errors with creating the table and importing data, since I did not have to correct permissions. I messaged Kiran about it this morning and he got back to me by the early afternoon. He put me in contact with Venugopal who is a Database Administrator, who he was able to solve the issues I was running into by the end of the day! Tomorrow I will finish importing all the data from Excel to Oracleand work out the syntax and smooth out any wrinkles that pop up with reading from and writing to Oracle.
                </p>
                <p>
                  In my downtime today, I transferred my saved model code that reads from and writes to Excel into new files that read from and write to Oracle in anticipation for future work. I also watched some videos on Fidelity Central about the kind of work FCAT is doing and strategies moving forward. It was interesting to hear about a whole other side of Fidelity that I am not familiar with or involved with. While I was waiting, I also attended a webinar about ‘Understanding Gen Z’ which was interesting. I don’t know if I agree with everything that was said about Gen Z during the webinar, but it was fun to hear what the older generations think. It seemed to fall in line with a lot of the opinions about Gen Z from the older generations via mainstream media and from adults throughout my life.
                </p>
                <p>
                  I also had my 1:1 with Nancy today. Mostly, we talked about current events and connected about our personal lives. Nancy also brought up the Power To Wow presentation exercise, which is planned for Thursday. This exercise is where we can present about any topic we want, whether or not it is related to our work. I started brainstorming, but have not decided on a topic yet. In my downtime between now and Thursday I’m hoping to work on this presentation. It seems like a fun exercise and I’m looking forward to hearing what the rest of our group will present about.
                </p>
            </div>
          </div>
          
          <div id= "July-24-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 24, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Manual Rules</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  oday I mainly focused on implementing two different ways to apply manually defined rules. I spent my morning finishing the first implementation that I started yesterday afternoon which uses stopwords and dictionaries. This implementation works by defining manual rules as keys in a dictionary of terms and their associated mapping for each level of commodity code as corresponding values. Then, in parallel with the predictions, if any of the dictionary keys are found in the total description field, the corresponding values from the dictionary are assigned to each commodity code level, otherwise a prediction is made based on the trained LinearSVC model as usual. It took some trial and error to get this working and formatted in the correct way but I was able to finish it by the end of the morning. However, as mentioned yesterday, this implementation applies manual rules based on the total combined description column, so if someone only wants to define a manual rule for one field without regard for other fields, then this implementation fails to capture the nuance. As a result, I spent the rest of the day implementing another way to apply manually defined rules. This method relies on for loops and if statements instead of dictionaries and stopwords like the previous version. This implementation explicitly states that only if one field is exactly equal to a manual rule, then the code will map specific values for each commodity code level prediction. Using for-loops and if-statements in this method allows for more user-defined nuance. Additionally, it makes it easier for users to see what they are exactly defining. It would be possible to implement dictionaries later on, but I would need to make a separate dictionary for each column field and loop through each dictionary. This seems unnecessarily complicated, but depending on how many manual rules are expected, I’m open to feedback if there are more efficient ways to implement this method. With both these implementations done, I plan to get feedback from Rajiv on Tuesday during our 1:1.
                </p>
                <p>
                  Today there was also an info session with some data analysts and software engineers that work directly with AI. The info session was pretty small, so people were able to ask pretty detailed questions. They talked about how they landed in data analyst and AI positions, how they chose Fidelity, and their academic trajectories. I asked a question about how Machine Learning resources are shared at Fidelity and one of the panelists linked me to a library of their resources afterwards. If I have downtime, I will check out this library and see if it is applicable to my team.
                </p>
                <p>
                  I did some preliminary online research about writing directly from a Python dataframe to Oracle. However, I would like to first check in with Rajiv and/or Kiran about the database table and if I should be writing to the database before I get started. I might set up a meeting with Kiran on Monday or I might hold off until after my and Rajiv’s 1:1 on Tuesday. Either way, next week I’ll get some feedback on my manual rules and proceed from there.
                </p>
            </div>
          </div>
          
          <div id= "July-23-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 23, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Pulling From Database</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I didn’t have any scheduled meetings after the daily scrum call, so I was able to focus on finishing documentation and making more progress on my Spend Classification tool. Additionally, I got an invite from Karin to present to her senior leadership team in 2 weeks so that I can get some feedback before presenting to the larger CTG leadership team.
                </p>
                <p>
                  This morning I finished up the required infrastructure document. Since I’m not done developing my tool, I will need to go back and add more infrastructure as I progress. I anticipate that I will need to add infrastructure relating to reading information from the database. If we end up using servers then I will definitely need to add infrastructure notes for that. I also spent some time creating a flowchart for my process of creating the tool. The flowchart is not very detailed and skips some of the smaller steps like Jupyter and the details of predicting purchase codes. I sent my documentation to Kiran and added it to the shared folder with Mallikarjuna and the India team. I’m not sure if they will be giving direct feedback, but this is my first pass at documentation so I anticipate that I will need to make some changes.
                </p>
                <p>
                  Next, I explored the data in the Oracle table that Kiran gave me access to. I noticed that some of the fields from the spreadsheet that David sent me are not in the table that I am accessing. I am guessing that those values were joined from another table. I will ask Rajiv and/or Kiran about this. I then used the instructions that Himanshu sent me a few weeks ago regarding cx_Oracle in order to connect to the database in Python. It only took a little bit of additional online research to pull the data from Oracle in the way I wanted. I was also able to figure out how to write Oracle data into an Excel sheet via Python which might be helpful for re-using the code I have already written which relies on Excel sheets. I couldn’t find any information about writing from Excel to Oracle via Python. I may need to explore if it is possible to write directly from Python’s pandas dataframes to Oracle. Alternatively, I may ask if it is acceptable for me to just write my outputs to an Excel file. For now, I will keep researching and exploring options, but if I’m still stuck, I’ll ask Rajiv or Himanshu
                </p>
                <p>
                  Finally today, I started trying to implement a way to define manual rules for Spend Classification in combination with my existing LinearSVC model. Currently, my approach is to use dictionaries and stopwords as recommended during my project demonstration last Friday. So far, I’m not able to get this working, but I’ll keep trying tomorrow. One potential problem comes from the fact that my model works by combining all the description fields into one ‘Total Description’ column. If someone only wants that item to be classified manually when one field is equal to a certain value without regard for if other fields for other items are equal to that value, then my approach might run into issues. For now I’ll keep working on the initial approach that uses the ‘Total Description’ field and I’ll tackle this specific issue around specifying one value for one field later on.
                </p>
                <p>
                  Tomorrow, I plan to continue researching if it is possible to write my predictions to the database. I will also continue to work on getting manual rules to work with the LinearSVC model. There are two intern webinars that I plan to attend about computer science AI which I’m looking forward to as well.
                </p>
            </div>
          </div>
          
          <div id= "July-22-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 22, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Documentation and Presentation Practice</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  The first thing I did this morning after the daily scrum call was finish up the quick guide that I started yesterday. I tested my code documents to ensure that everything was running smoothly. I then added all the necessary documents to a shared file which included scripts and Excel sheets along with my quick guide. This was sent over to Mallikarjuna and the rest of the India development team that I demoed my tool for last Friday. It seems like everything was sent smoothly, but I’m ready to troubleshoot if my code has errors or if the team has suggestions for how to make the tool more efficient.
                </p>
                <p>
                  Once this was done worked primarily on my presentation for the rest of the morning. I ran through my presentation and realized I would be way over the 5-7 minute time limit. I edited my slides pretty significantly so that I would only include the most necessary information. I also spent some time reading over and editing my script. I was able to get my presentation to about 7 minutes by the end of the morning but I’m still a little over the time limit.
                </p>
                <p>
                  I started my afternoon by attending a webinar about how to have an effective resume. There was some insightful advice about how to catch a recruiter’s eye with your resume. With this information in mind, I can edit my existing resume and make sure I write the description for my Fidelity internship with these in mind. There is also a service for recruiters to review your resume which I might take advantage of if I have time. I also volunteered to be interviewed for Digital Champions to provide some feedback about the applications used within Fidelity.
                </p>
                <p>
                  This afternoon I practiced my presentation with Nancy, Benjamin, and Gabe. For the presentation I basically read off of the script that I had finished preparing this morning, which I was worried about since reading off of a script can come off as monotonous. But it seems like Nancy, Benjamin, and Gabe didn’t find an issue with my pacing or tone. The main thing I was concerned about was timing. Benjamin mentioned that I could cut some things out of my demonstration since it was covered in my ‘Results’ slide. Otherwise, it seems like my presentation practice went well! After hearing their feedback, I’m definitely feeling less nervous about presenting. Rajiv mentioned that I might need to present for Karin and her senior staff to get some feedback before my final presentation for all of CTG’s senior leadership, and after practicing for Nancy, Benjamin, and Gabe, I feel ready to present for Karin.
                </p>
                <p>
                  Kiran requested that I start the documentation for my tool. This includes a file that states and explains all required infrastructure and a flowchart of my process of developing the tool. I started creating the required infrastructure document since it had a lot of overlapping information with the quick guide that I sent out this morning. I started planning out what level of detail might go into the flowchart but I haven’t gotten around to making it yet.
                </p>
                <p>
                  Tomorrow, I plan to create the flowchart and finish the required infrastructure document. Once this is done, I will use Toad and cx_Oracle to pull information from the database into an Excel sheet via Python. This will be my first step in moving off of the Excel and onto the database.
                </p>
            </div>
          </div>
          
          <div id= "July-21-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 21, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Setting up Toad</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent most of my day today getting Toad properly set up and connecting to the database. This morning after the daily Scrum call and the weekly release update meeting, I entered the queue for techworks to finish installing Toad, which they started installing yesterday. Someone at techworks was able to help push Toad onto my machine, but unfortunately they had pushed the program onto the wrong location, so I wasn’t able to access it. After consulting with Poornima about my error, I went back to techworks and another agent helped me move Toad and Oracle to the correct location. During my 1:1 with Rajiv, he explained some database terminology and information about the data server set up and disaster recovery. Once Toad was properly installed, I tried to connect to the database using the information that Kiran had sent me last week. Unfortunately, there was something wrong with the username and password combination. I spoke to Rajiv about the error in case I was inputting the fields wrong, but based on the error I was getting, he advised me to speak with Kiran. After some troubleshooting, Kiran was able to point me in the right direction and I was able to successfully connect to the database. I spent a little while exploring the table I was given access to. Now that I can connect to the database, I will look into how I can pull information from the database to be used in my tool.
                </p>
                <p>
                  I also had my 1:1 with Derick today. He is going on vacation for the next 3 weeks, but I will see him in the week when he comes back which will be the last week of my internship. Today we talked about the AI articles from the AI club’s website together. Specifically, we talked about AI and human interactions and the way this can impact different industries. When I told him about my struggles with connecting with the database, he assured me that working with databases often comes with issues regarding permissions, data access, and information flow. It was nice to know that the items I was struggling with are common points of frustration. Since we are meeting during the last week of my internship, we agreed that I could practice presenting my powerpoint for the Bi-Monthly meeting during this last meeting. This gives me the opportunity to explain my project to him and to practice presenting.
                </p>
                <p>
                  In the afternoon, Kiran also reached out to me and asked me to share my code with the folks from the India team to whom I presented my code last Friday. I shared the preliminary code files with them, but Kiran also asked me to share my Excel files and a quick guide for how to run my code. I started working on the quick guide today, but was not able to finish. Tomorrow, I plan to complete the quick guide and send that over ASAP. Hopefully everything goes smoothly.
                </p>
                <p>
                  Today I also received news that my end-of-internship presentation is being pushed to August 12th. This gives me more time to practice my presentation and I’ll be able to include more updated work since August 12th is closer to the actual end of my internship. I sent my presentation over to Rajiv for a quick review, but the final version of my presentation will likely be different to this one since hopefully I will make more progress in the next 3 weeks. I still plan to practice my presentation tomorrow with Nancy and our intern group since I want to make sure I am within the time limits. 
                </p>
                <p>
                  Tomorrow, I will send out the quick guide and the remaining documents that Kiran requested to the India team. I also need to finish preparing my slides and I will probably need to cut out some information to keep it within 5-7 minutes before I practice my presentation with Nancy. Additionally, I volunteered to be interviewed for Digital Champions which is supposed to inform how Fidelity works online. If I have time in the afternoon, I will continue using Toad to explore the data.
                </p>
            </div>
          </div>
        
          <div id= "July-20-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 20, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>AI and Oracle</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I finished putting together my presentation for Friday’s end-of-internship CTG event.  I edited my script and put together my ‘Demonstration’ and ‘Results’ slides. I decided that I would just make my presentation based on what I have done so far and any progress that I make from this point onward will be included in my presentation for the Bi-Monthly meeting instead. The tool that I have right now is well-functioning and I understand each part of it, so I feel ok about my ability to present it for Friday’s meeting. There was an email that had more information about what should be on the presentation, which includes a ‘Feedback’ section and states that the presentation should be 5-7 minutes long. I finished the ‘Feedback’ slide this afternoon and I will time myself presenting tomorrow to see if I am within the time constraints or if I need to cut our certain parts.
                </p>
                <p>
                  This morning I also read through some of the AI Club’s articles. There were some interesting parts about how people don’t currently like robo advisors so we’ve gone back to a robot-human hybrid system and about an AI therapy chatbot called Woebot that can decipher emotions based on your speech. There were also some articles about how AI is being applied to current events like COVID-19 or grading policies. All of these articles bring up some interesting topics that I hope to discuss with Derick tomorrow. I might read a few more articles tomorrow morning if I have time.
                </p>
                <p>
                  Later today I had my 1:1 meeting Nancy. I mentioned that I had my end-of-internship presentation on Friday and that I was a little nervous about it. She offered that I could practice presenting to a couple people our intern group and get some feedback on Wednesday. She also suggested that we could plan events in the future to practice presenting, since I mentioned that presentations are one of my weak points since I find it hard to think on the spot and I often rush through my points. We also discussed mobility at Fidelity and how you can move teams if you are unhappy on your current team. It’s nice that you can explore different areas without changing companies this way.
                </p>
                <p>
                  In the afternoon, Poornima helped me get started with installing Oracle and Toad. In order to install Toad, I first had to install Oracle. Oracle took a while to install, so in my downtime, I worked on the beginning part of my presentation for the bi-monthly meeting which I can also use for any demonstrations or presentations about my project in the future. This powerpoint is different from my end-of-internship presentation, since it includes more technical information about the algorithms and models used and includes less about my personal learning experience. I finished the first portion of this powerpoint, which includes the problem statement, my general approach, and explanations of both TF-IDF and LinearSVC. I’m holding off on completing more of the presentation since I anticipate that a lot of things can change in the month between now and the Bi-monthly meeting. Once we get closer to the Bi-Monthly meeting, I’ll work on more of the demonstration and the walkthrough of my code. I was able to successfully install Oracle, but ran out of time to install Toad. I went to techworks for assistance to get past the administrator access, but it seems like techworks is quite busy today so they weren’t able to get to my position in the queue before the work day ended. I’ll try again tomorrow.
                </p>
                <p>
                  Tomorrow, I’ll finish installing Toad and start exploring the database. I have my 1:1 with Rajiv tomorrow morning so maybe he can help me get started with navigating Oracle. I’ll also update him on my progress with predicting commodity codes. Once I explore the database, I can start pulling in data via Python. I also have my 1:1 with Derik tomorrow, so I might read more AI articles before our meeting and jot down some notes of what to discuss. Lastly, I plan to edit and practice my presentation if I have time.
                </p>
            </div>
          </div>
        
          <div id= "July-17-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 17, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Presentations and Printing</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  For most of today I continued working on my Spend classification tool trying to find the most efficient way to print the outputs. Working off of yesterday’s approach, today I worked on a method that prints the predictions into the original data’s existing spreadsheet for all 3 commodity codes using one file. This fulfills the request to have all of the predictions in adjacent rows to the original data for comparison. The method of training the model and making the predictions all in one file takes about 6 minutes to run which is much more efficient than yesterday’s approach. This also does not require clearing all the variables between each run. I also spent some time moving my trained models to joblib files for better efficiency. The method of training the model, saving this model, and running predictions in a different file takes an accumulated time of 5 minutes. One other benefit of this saved model approach is that it requires less memory. I think for the purposes of this project, using a saved model makes more sense. Not only is it more time and memory efficient on my sample data, but if you wanted to train the model on one data set and make predictions for a new data set, the saved model approach would be more efficient. 
                </p>
                <p>
                  Kiran granted me access to the database this afternoon and Rajiv sent me a license code. However, I’m a bit lost on how to get it set up. Rajiv recommended that I connect with Poornima about setting up the necessary tools, since she set it up pretty recently. I set up a meeting with her for Monday afternoon. Once I get this set up, I will be able to explore the database table that I have access to. I think it would be beneficial to access the database and look at the data before I work with it directly.
                </p>
                <p>
                  Today, I also got to showcase my project to Kiran and some of his India development team. I got some great suggestions about how to implement manual rules efficiently using dictionaries and stopwords, which I hadn’t even thought of! This gives me a good direction to go in with regards to implementing manual rules and I feel a lot less stuck. Overall, the presentation went pretty smoothly but I feel like I rushed some parts. Rajiv mentioned that I might be presenting my project to Janice and the rest of APT at the next bi-monthly meeting (which is during the last week of my internship). I think I’ll need to have a full powerpoint presentation prepared to stay on track for this meeting instead of just using talking points and demonstrations like I’ve been using so far. I’m a bit nervous for this presentation since it's a larger group of associates that I don’t know very well, but maybe I can practice with Nancy and/or Derik as the date approaches so I can fine-tune and practice my presentation. Something this demonstration made clear to me is that I’ll need to assume no prior knowledge of my project. I’m usually talking to Rajiv or Kiran about my project, but since they are already very familiar with my project, I’ll need to change the way present for other groups. Speaking of presentations, I worked on my end-of-internship presentation script a bit more today. I might practice this presentation with Nancy this week if she has time, otherwise I’ll run through it on my own. I have most of the presentation done, but I need to think about my demo and my results slides a bit more. Maybe I can even add a ‘Next Steps’ slide since I’ll be working on this project for another month. I plan to ask Rajiv what he thinks and confirm the length of the presentation during our 1:1 on Tuesday.
                </p>
                <p>
                  Derek mentioned the AI club during our meeting, so I spent some of my time today browsing their site and resources. Some of the resources seem very advanced and mention topics beyond my scope of knowledge. However, I found some interesting introductory articles about FCAT and Machine Learning that I plan to read Monday morning in my downtime. 
                </p>
                <p>
                  Next week there are a couple of things to look forward to. The first is the end-of-internship presentations. I’ll get the opportunity to present my project to CTG senior leadership and my fellow CTG interns. I’m excited to hear about what other CTG interns have been working on this summer! I’m also eager to start working with the database now that I have access. I’ve never worked directly with a database, so this will be a new experience for me. I’m happy with the progress I’ve made this week in regards to the transition to predicting commodity codes and different networking opportunities! :)
                </p>
            </div>
          </div>
        
          <div id= "July-16-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 16, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Formatting Predictions</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  For most of today, I worked on reducing runtime and attempted formatting my predictions in the way that Kiran requested. I also spent a decent amount of time working on my end-of-internship presentation In my previous version, the model was making the predictions for all 3 levels of commodity codes in one file, but this led to a very long runtime. Today I split the predictions into 3 files. I wrote the code in a similar format to my purchase code prediction model. The problem with this is that the predictions for each level of commodity codes are in separate files and it is inserted to the format of the original data. However, this process is a lot faster than writing all 3 levels at once. I also found that clearing the memory of previous variables using ‘%reset -f’ in the terminal between runs will make the process faster, so I may need to add a note for users to do this in between runs. I was able to finish most of my presentation today. There are a few portions that will be completed closer to the presentation date since they will talk about portions of the project that I have not yet completed. I might edit my presentation script tomorrow, but for now I am happy with where this presentation is.
                </p>
                <p>
                  Today, there was also a webinar for elevator pitches. They talked about the purpose of elevator pitches and the key components that should be present in an elevator pitch. Most of this information was pretty repetitive and included topics I had learned in interview preparation workshops but I thought the examples that they showed were informative. Rajiv got approval to extend my internship program by 2 weeks, so I will be working until August 21 instead of August 9. I’m excited to see what I can accomplish with this extra time. It seems like some other interns are also getting their internships extended like Renbin from the CTG intern group and Benjamin who I spoke to yesterday. I’m hoping that more interns will get their programs extended so we have extra time to connect!
                </p>
                <p>
                  Tomorrow, I plan to continue working on the formatting of my outputs so they can be printed into the same Excel sheet but the code can be run separately to keep efficiency. I still have yet to receive a response from Kiran, so I might reach out to him again tomorrow. I also have my demonstration for some members of the India development team tomorrow, so I will likely spend my morning preparing for this.
                </p>
            </div>
          </div>
        
          <div id= "July-15-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 15, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Fixed Memory Error :)</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning after the weekly update call, I got in contact with Techworks to try again to fix the memory allocation error. Fortunately, I was able to clearly communicate the error that I was having and how Rajiv suggested to resolve the error. Techworks was able to enter administrator access so that I could update my machine settings and resolve the memory allocation errors. With this error fixed, I should be able to move forward with my Spend classification tool to train and predict using more data.
                </p>
                <p>
                  This morning I also had my meeting with Derik and Danny. Danny works in Data Analytics and Insights and explained the work he is doing. He showed me how he runs automation software on information from databases. Maybe I can ask him for advice in terms of pulling data from a database, processing the data, and writing an output back to the database. He gave some great insight about how Fidelity uses automation in combination with machine learning and how Fidelity keeps an eye on new technology. Derek also brought up how data is a valuable commodity in today’s world since a lot of processes depend on the data we have stored. This gave me something new to consider. So far, I’ve been following a track to prepare for Software Engineering roles, but Data Engineering is a field that I might look more into. Danny and Derik pointed out that in order to run important algorithms in machine learning, you have to be able to clean and process your data before you use it, which is something I’ve witnessed this summer. Danny also mentioned that software and hardware go hand in hand, so learning more about hardware can improve your software. He showed an example of how he ran his code in parallel to maximize CPU and make his code more efficient. I’ll keep this in mind as I continue developing my tool to see if I can apply these concepts to increase my tool’s efficiency!
                </p>
                <p>
                  Early this afternoon, I connected with Benjamin who is another LEAP intern. He talked about his project, which reads and processes CSV data. He also has a side project that works with Outlook to help people communicate and connect more smoothly. It’s interesting how diverse the intern experience can be even within the technology sector. This is encouraging in that if I am extended an offer for next summer, I may have the opportunity to explore something completely different!
                </p>
                <p>
                  For the rest of the afternoon, I worked on my Spend classification tool and my end-of-internship presentation. My session with techworks seemed to fix my memory allocation issue! I spent a while altering my training and testing data to take advantage of the whole data set given to me. Eventually, I was able to get the commodity code predictions working and printed to a new Excel sheet. Now that I am training on more data, my accuracy issue with Level 0 commodity codes is resolved! All 3 commodity code levels (Level 0, 1, and 2) are at 97-98% accuracy which is great! However, since I am now running 3 prediction models and using a lot more data, my program is much slower. Currently, all the predictions are happening in 1 file, but it might be beneficial to break up the predictions not only for efficiency, but also for usability in case users only want to view predictions for one level. I will work on implementing this tomorrow. I also want to isolate all the rows where the predictions are incorrect and print them into a separate spreadsheet for ease of analysis. Since my code was taking a while to run, I worked on my presentation for next Friday, where all the CTG interns will present what they’ve learned/worked on.
                </p>
                <p>
                  Tomorrow, I plan to continue working on my Spend Classification tool. I will separate predictions into 3 files and isolate the rows where my predictions do not match the actual classification. I also plan to continue working on my presentation if I have downtime. I don’t have any planned meetings tomorrow, but I might reach out to Kiran to double check on the status of getting access to the database.
                </p>
            </div>
          </div>
        
          <div id= "July-14-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 14, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Multilevel Commodity Classification</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent most of my morning getting the predictions for Level 0, 1, and 2 commodity codes working on 1k rows of data. Since I don’t have the memory allocation errors fixed yet, I’m training on about 3k rows and testing on 1k rows. This allowed me to work through more basic bugs and fix formatting before I move on to larger data sets. It seems like my model predicts Level 1 and Level 2 pretty accurately (97%), but has some trouble with Level 0 predictions (72%). I’m not sure if there is some fundamental flaw with my program or if this is due to a lack of robust training data. Once I fix my memory allocation error and am able to train on more data, I’ll be able to see if I need to go back and fine tune my model to work with Level 0 predictions.
                </p>
                <p>
                  Later this morning, I had my 1:1 with Rajiv. We talked about my current status with the project. I updated him on the information that Kiran gave me yesterday, where I’m stuck, and what I plan to do next. He suggested a method of implementing manual rules, which relies on a field in the database that informs whether or not rules have been defined for a column. He also tried to help me troubleshoot the memory allocation error I was running into. Ultimately, I’ll have to go to techworks to see if they can bypass the administration access or provide me with some other workaround. A few interns in the CTG group were talking about final presentations and Rajiv confirmed that there is a brief presentation where interns talk about what they learned throughout the summer, so I might start preparing for that.
                </p>
                <p>
                  Around noon, there was an info session about the LEAP program, which is meant for new college graduates joining Fidelity as Full-stack Software Engineers, Data Engineers, or Systems Engineers. I’ve heard a lot of great things about the LEAP program from Nancy, Rajiv, and others, so I was excited to learn more. The LEAP program is meant to train new associates and make the onboarding process smoother. Something I found particularly helpful is that you know your manager ahead of time and you can tailor your learning opportunities based on what team you will be on. I might ask Nancy more about her experience with LEAP, since I’d like to know more about LEAP or similar onboarding programs.
                </p>
                <p>
                  In the afternoon, I caught up with Derik. I asked him about how he started at Fidelity and how he got to the position he is working in today. His experience is different from Nancy’s so it was cool to hear a different perspective. He also talked about the workflow his team uses, which is different from our team’s workflow. Given the nature of his projects and his smaller team, they use less of an Agile sprint methodology and instead run longer projects. I wasn’t aware of how new Agile was to Fidelity (introduced 2 years ago) so I was under the impression that most teams were using Agile. It was eye-opening to see how different teams with different needs might use other methodologies that work better for the projects that they are working on. Derek also mentioned that the AI club has some interesting resources and articles, so I might look into some articles to discuss in our next meeting!
                </p>
                <p>
                  I contacted techworks about my memory allocation error, but I think they misunderstood my question, so I’ll try calling again tomorrow to resolve my issue. I also contacted Kiran to clarify what implementation he wanted for manually adding rules and I’m hoping to hear back from him tomorrow. I started thinking about what I might include in my end-of-internship presentation and I might start working on my presentation tomorrow if I have downtime. I’m usually not a big fan of presentations, but I’m eager to share my project with other interns and to learn about what they’ve all been working on.
                </p>
            </div>
          </div>

          <div id= "July-13-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 13, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>New Requests</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning started off pretty similar to how I left off last week. After attending the scrum meeting, I spent the rest of my morning completing the machine learning course that I started on Friday. A lot of this course was a good review from the beginning research phases of my project and showed ways that I could apply different concepts. Some new concepts that I learned were about regression and reinforcement learning. These concepts are not directly applicable to my Spend classification project, but I think that these general concepts are good to know. Additionally, Derek set up a meeting with one of his coworkers in data analytics and insights for Wednesday, so I completed a course on data analytics so I will be able to ask more thoughtful questions during our meeting and so I can understand the kind of work he does more easily. Lastly, I completed a course on how to be a better mentee. Mentor relationships are heavily emphasized at Fidelity as being a good way to network and grow in your professional life, so I wanted to learn more about best practices for how to get the most out of my mentor relationships. There are a few other LinkedIn Learning courses that I can complete, but for now I think I’ll take a break from these courses, since they’re getting a bit monotonous.
                </p>
                <p>
                  This afternoon, I caught up with Nancy for our 1:1. I mentioned where I was stuck with my project since I was waiting on responses from a few people. Nancy suggested that in addition to LinkedIn learning, I could also spend my downtime networking or even ask my team if they need any help. I set up a quick networking meeting with Benjamin from our intern group on Nancy’s suggestion. Nancy and I also talked about our group and how we could connect more. After the meeting, I spent some time trying to find games we could play together, and I have a few good options!
                </p>
                <p>
                  This afternoon, I also attended a Virtual Career Showcase for the Emerging Leaders Group (ELG), which is a cohort for onboarding those with liberal arts undergraduate degrees. While I am more interested in joining the LEAP program, I thought it would be interesting to hear about other programs and get an idea of other options that exist. This showcase was pretty interesting and it seems similar in format and length to the LEAP program, but of course the contents are different.
                </p>
                <p>
                  Later in the afternoon, I caught up with Kiran briefly. He mentioned that he brought up my project to Janice and a few members of the India development team. It seems like people are pretty interested in my project! :) This is really exciting to me and I’m glad that people are interested in the work that I am doing. Kiran mentioned that I could consider doing a demonstration of my tool for some members of the India development team later this week if we can find a time that works with everyone’s schedules. Kiran also brought up my project with his boss, who had a few suggestions for where to expand on this project. Previously, Daniel and David mentioned predicting the Level 2 commodity codes, but Kiran’s boss mentioned that it would be helpful if I could also predict the Level 1 and Level 0 commodity codes. These predictions would be printed in adjacent columns to the existing correct data in the spreadsheet or database. This is something that I can work on integrating. Kiran also mentioned that it would be helpful to be able to add manual rules somewhere. This implementation is something that I will have to think about more deeply since it doesn’t work smoothly with my existing model. I may have to add a file for where you can hardcode rules and apply the corresponding commodity codes, but I’m afraid this will harm the efficiency of the project. The last thing Kiran mentioned was that we might be implementing my project with Snowflake, so I might look into taking an introductory Snowflake course.
                </p>
                <p>
                  I worked on expanding the current code for Level 2 commodities to work on Level 1 and Level 0 commodities, but I’m still struggling with some preliminary errors. I plan to continue working on Level 0, 1, and 2 predictions tomorrow and start thinking about how to implement manual prediction rules. I also have my 1:1 with Rajiv tomorrow, where I plan to bring up the memory allocation errors I was running into last week. Fidelity also has its LEAP program showcase tomorrow, where I’m eager to learn more about since I’ve heard so much about it!
                </p>
            </div>
          </div>
        
          <div id= "July-10-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 10, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Databases and Data Science</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today was a very laid back day, since I’m still stuck and can't progress with my Spend classification tool. I haven’t yet received a response from Kiran about getting a read-only username and password to the database. If I don’t receive a response by next week, I’ll send a follow up message, but it seems like there are some issues with the databases currently, so it may be a little while before I have access. I am also still stuck with regard to predicting commodity codes since I’m still running into memory allocation errors and do not have administrator access. Rajiv mentioned that he has been busy and will help me as soon as possible. I updated him on the fact that I am learning some new topics using LinkedIn learning in the meantime. The only other aspect that I can work on for the Spend classification is servers, but based on what Don said, it seems like the decision of whether or not to even use a server is something we will need to discuss as a larger group when we get closer to the time of implementation
                </p>
                <p>
                  Since I have a lot of downtime while I wait, I’ve been using LinkedIn learning to learn about a variety of topics. Today I completed a course on databases and a course on data science. The database course taught me some general concepts about database design, use, and basic SQL commands. I think the information from this course will be useful for when I have access to the Oracle database and need to pull Spend data. The data science course taught me more general information about how to explore data, answer hypothesis questions, and the difference between data science and statistics. I also started a general machine learning course, which was informative for learning about different applications of machine learning that I can look into later.
                </p>
                <p>
                  At midday, there was a panel discussion with previous tech interns. We got to hear perspectives from Kyle, who is on his third Fidelity internship, Alejandro, who is currently in the LEAP program, and Revanth, who recently graduated from the LEAP program and is currently working full-time. It was great to hear their experiences and advice surrounding the internship program and the onboarding process.
                </p>
                <p>
                  Today I also reached out to Derick with some generic questions about getting help and moving past roadblocks. Next week, I hope to move forward with the Spend Classification tool. Even if I remain stuck, I have access to plenty of learning resources through LinkedIn learning and I can reach out to Nancy and Derick to see if they have time to give advice about career building and talk about their experiences at Fidelity. There are also a number of intern webinars next week to look forward to, surrounding career showcases, virtual town halls, and elevator pitches.
                </p>
            </div>
          </div>

          <div id= "July-09-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 9, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Fixing Stopwords</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I had a morning meeting with Nancy today. We caught up on work and I told her about my presentation yesterday. I mentioned that I get a little nervous giving presentations and she offered to help me practice for presentations in the future. If she has free time, I’ll probably take her up on this offer since I think it’ll help me be less nervous about presenting in the future. She also mentioned that as part of the LEAP program, everyone had to give a 20 minute presentation about a topic of their choice. This sounds pretty intimidating, but all of my presentations are academically oriented, so maybe it would be easier or just different to give a presentation about a hobby. Nancy suggested that we could even do a 5-10 minute version of this with our intern group if people aren’t too busy. I also asked Nancy more about her experience with the LEAP program. I’ve been hearing a lot of great things about LEAP and since Nancy took part in the program not too long ago, I thought it would be informative to hear her thoughts. From what she shared, it sounds like a lot of fun! It seems like a great way to get adjusted to the work environment, bond with other associates, and learn new skills. I think that I would definitely consider joining the LEAP program in the future if I was given that opportunity. :)
                </p>
                <p>
                  For the rest of the morning, I worked through some of the issues I was having yesterday with combining stopwords and lemmatization. I ended up directly altering the stopwords file from NLTK to include the lemmatized stopwords. This means that the new stopwords are hardcoded in, which might not be the most sustainable solution, but I wasn't able to find an alternate solution that wouldn’t mess with the efficiency of my existing program. Additionally, excess stop words that aren’t covered by this process shouldn’t be too big of a deal. Since I’m using TF-IDF, stopwords likely have a high document frequency, so they shouldn’t cause too many errors with the categorization. I reimplemented lemmatization into the commodity prediction program and it seems to be running smoothly.
                </p>
                <p>
                  In the afternoon, there was a webinar about Diversity and Inclusion. It was eye-opening and inspiring to hear about the experiences of associates from minority groups, specifically Black associates, in light of recent events and the discussions being raised about racial inequality after George Floyd’s murder. Associates discussed their experiences with microaggressions in the workplace, how they raised their voices to speak against injustices in their personal and professional lives, and inspired us to take action against racial injustice.
                </p>
                <p>
                  Throughout the rest of the day, I continued trying to work around the memory errors I was getting regarding allocating memory for a large array. There were a few times where the code ran successfully for 100k rows, and I got an accuracy of about 98% which is great! However, it doesn’t run without error consistently for anything greater than 50k rows. After some online research, it seems like I could override this error by changing some file size settings. However, in order to change these settings, I need administrator access. I messaged Rajiv about this error and asked if there was any way to get an admin to bypass these settings, or if it would be better for me to just stick with training on 50k rows even if it is less accurate. It seems like Rajiv was stuck in back-to-back meetings today, so I wasn’t able to get a response today. In my downtime, I decided to test how accurately the model could predict with 50k rows of training data. On 100k rows, the model is 93% accurate and on all 235k rows the model is only 74% accurate. So as predicted, more training data definitely leads to better results.
                </p>
                <p>
                  During my downtime in the afternoon, I also watched a course comparing Waterfall and Agile frameworks. I think this helped me understand more of the benefits of using Agile. I’m hoping to get access to the database via Kiran or an administrator settings override via Rajiv in the near future, but I understand that they are busy. I’ll ask Rajiv if he has suggestions for other tasks I can undertake or other areas for me to look into while I am waiting on these components to move forward with my tool. Otherwise, I can look into more career development courses on LinkedIn learning via Fidelity central. At the end of the work day, I came up with a question for Derick about his decision to get an MBA, which I plan to message him about tomorrow. I also made a collage of my interests for an ice breaker for my mentor group chat with Nancy in the afternoon. I hope to make progress with the Spend classification soon, but in the meantime I can busy myself with networking and career development!
                </p>
            </div>
          </div>

          <div id= "July-08-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 8, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Update Meeting!</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning there was no scrum call since the whole APT team was gathered for a Bi-Monthly team meeting. Janice led the meeting and there were plenty of new faces. A couple of teams talked about the broad overviews of their projects and what they’re currently working on. Rajiv and Ramya from our team explained the database-related work that our team is doing. It was interesting to see how this larger meeting differed from the usual scrum calls, which are much smaller and much more detailed. This call discussed longer-term plans, was more like a presentation than a discussion, and had a lot more people.
                </p>
                <p>
                  Today I also had the opportunity to explain my progress to some familiar faces from the business team. David, Cameron, Daniel, Kiran, Rajiv, and Mallikarjuna were present at this meeting. Kiran and Rajiv were already pretty much caught up from Monday’s meeting, but this was the first time that David, Cameron, and Daniel were able to see the code that I had been writing. Kiran invited Mallikarjuna onto the meeting and it was nice to have a fresh perspective. Since the last meeting was when I was still in the initial research phase of the project, I covered pretty much all the code, algorithms, and applications of the model. Based on Kiran’s suggestions from Monday, I started off by explaining the high-level concepts of how my tool worked and explained that I was using a widely-known machine learning algorithm. I then walked through the basic outline of my code, with more focus on TF-IDF since this was how the model was making its own ‘rules’ about how to categorize data. From here, I showed how I applied the model to make predictions for defined purchase codes and compared these predictions to the actual purchase codes. At this point, I answered a couple of questions about TF-IDF and LinearSVC. I then moved on to explain how my code made predictions for unspecified purchase codes. David brought up that I could also look into predicting a different field called commodity codes using purchase codes as part of the training description. Since the sample data I currently have does not include the commodity codes and I don’t yet have access to the database, David and Daniel offered to send me an updated spreadsheet with commodity codes until I had access to the spreadsheet. Kiran and Rajiv also brought up how we were working reading directly from a database and using a server. We discussed these points for a little while, but it seems like we’ll discuss this in more detail as the tool becomes more advanced and more applicable. Overall, it seems like I’m headed in the right direction with what I’ve done so far! It doesn’t seem like the accuracy or efficiency of the tool need to be improved very much. The next steps are to alter my code to make predictions for commodity codes and once I have access to the database, I’ll be able to work on reading from the database directly.
                </p>
                <p>
                  I also had a meeting with my new FYPN mentor Derick today. We mostly talked through introductions about my previous CS experience, his work history at Fidelity, and his academic history. I mentioned that I was interested in AI and he offered to reach out to some team members to see if I could shadow or get connected with them. He also told me about some interesting ways that Fidelity is using robotics. Since he’s more involved with data science and he mentioned that he got an MBA, I am excited to ask him more about his career path and choices, since I’m considering getting an MBA at some point. We have weekly meetings set up, but I hope to message him between meetings as well.
                </p>
                <p>
                  For the rest of the day, I worked on predicting commodity codes as David suggested. For now, I’ve removed the lemmatization steps since it was causing some warnings with the stop words. Once I have a prototype that can successfully predict commodity codes, I plan to work through these smaller errors with text preprocessing. I made a few alterations to my purchase code prediction program, but I’m receiving errors about being unable to allocate memory for my data. :( It seems like my data is too large to convert to an array with the added commodity code column. I can train my model on 50k rows, but I run into errors for anything larger. I’m still working through these errors, but I might need to reach out to get help or override some settings to truly resolve them.
                </p>
                <p>
                  Tomorrow, I have my 1:1 with Nancy, where I plan to ask about mobility, getting placed on teams, and adjusting to new teams. There’s also a webinar about Diversity and Inclusion for interns in the afternoon which I plan to attend. I might reach out to Derick if I come up with any questions throughout the day about his work. Otherwise, I’ll continue to work on getting the commodity code predictions and hopefully I’ll be able to work around the memory errors.
                </p>
            </div>
          </div>

          <div id= "July-07-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 7, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Meeting Prep And cx_Oracle</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I started my morning by reaching out to Himanshu to ask for his advice on reading information from oracle databases using python. He recommended that I import the cx_Oracle package and gave me a lot of great information about how to set up an environment and proxy to access a database. He provided me with some of the code he used so that I had a starting point for what information I would need in order to read information from the database. He also showed me an example of how he processed information from the database by iterating through different rows. Today I also had my 1:1 meeting with Rajiv. Since I updated him and Kiran on my project yesterday afternoon, I didn’t have anything new to report today since he was already up-to-date. I mentioned that Himanshu had given me a lot of great advice for working with databases and Rajiv gave me some additional insights. He demonstrated what kinds of commands can pull information directly from a database and export the information as an Excel sheet, which is what I have been working with. He suggested that I might be able to just create an intermediary step to turn the information from the database into an Excel sheet and then my existing code would work just as it does now. He also explained what the different pieces of information that I need to access a database mean in context so that they don’t seem like such abstract concepts.
                </p>
                <p>
                  This morning I also attended the team’s weekly update meeting. As per usual, I had a general understanding of what was being discussed in terms of dropping, inspecting, and changing components, but I wasn’t able to follow the specifics. Something interesting about this meeting was that there was a lot of back-and-forth discussion about the best procedure to address a task. I thought it was interesting how some approaches favored completing tasks as quickly as possible, while other approaches favored a more consistent pace to account for people’s bandwidths and someone brought up that being too ahead of schedule might mean that the project could grow in scope from what was originally agreed upon. Listening to the discussion gave me a better understanding of how different people have different styles of working and how it's important to come to a consensus or a compromise as a team.
                </p>
                <p>
                  I messaged Kiran to ask for some of the information that I would need to access and connect to the database after my meeting with Rajiv. It seems like Kiran is quite busy as he has a lot of back-to-back meetings, so I didn’t receive a response today, but I can ask again during our larger meeting tomorrow. Connecting to the database is not an urgent matter, so I spent some time on my personal career development while I was waiting. I watched some online courses about office politics and how to succeed in a new job. I think I can apply a lot of these concepts to this internship as I move forward, to my next internship, and to my career in the future. These courses highlighted the importance of professional relationships and finding mentors. As a matter of fact, I applied for another mentor through FYPN last week, specifically in the field of AI. Today my mentor, Derick, reached out to me and set up an introductory meeting for tomorrow! I compiled a few questions to ask him during our meeting about his work, how Fidelity uses AI, and how he got involved with AI. Since my project this summer is concerned with NLP I am interested in hearing more about applications of AI and how he decided on a career in AI.
                </p>
                <p>
                  This afternoon, there was a webinar about managing money from Personal Investing specifically for interns. We covered budgeting, credit, debt, investing, and retirement. It was nice to get some advice specifically directed toward young people and I can definitely apply what I learned to my personal finances. I really like that Fidelity has specifically created programs to help not only customers but also associates with their finances. :)
                </p>
                <p>
                  For the rest of the afternoon I worked on preparing for my meeting tomorrow with the Business team. I feel pretty prepared, but I’m just hoping to cover all the points I want to and truly showcase what I’ve been able to accomplish in the last few weeks. I’m definitely ready for some new feedback and an idea of what steps I can take to expand the project to beyond what I’ve done so far. I’m also excited to meet my new FYPN mentor Derick tomorrow!
                </p>
            </div>
          </div>

          <div id= "July-06-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 6, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Servers and Lemmatization</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning I had my meeting with Don to discuss the possibility of using a server for my project. Don mentioned that I should consider a few items before jumping into using a server, namely the scope/computational power of the project, how many people will be using the application, and how much maintenance is needed. He gave two examples of servers: VM and C2C. A VM server is very powerful and does not require much maintenance, but it takes a few months to get approved, which might not be viable for my project. Additionally, since my project would not be used enterprise-wide a VM server would be overkill. A C2C server only takes a few hours to get approved and would be more appropriate for the scope of my project, but it would require a lot more maintenance. I think this is something I will need to discuss more with Rajiv and Kiran before deciding if a server is really necessary for this project. A more likely solution is that I’ll find a way to get my program onto the desktops of those who will be using my tool. Don also talked to me about the LEAP program for newly hired associates Fidelity and how this allows for accelerated career growth and an easier transition in Fidelity. I’ve heard a lot of great things about Fidelity’s LEAP program and Fidelity’s work culture as a whole and it’s given me a lot to think about when it comes to thinking about my future career path.
                </p>
                <p>
                  I also worked on a new format for writing outputs today, where the newly predicted purchase codes can be written directly into the corresponding column of an existing spreadsheet. I’m still not sure what the format the final product will be interacting with, but if it is contained in an Excel spreadsheet like the sample that I was sent, then this would be a good feature to have implemented. Otherwise, I can work with the new format once I get confirmation from the Business team.
                </p>
                <p>
                  Today I also worked on implementing lemmatization as part of the text preprocessing. Lemmatization allows different forms of a word to be grouped together and analyzed as a single item. For example, run, running, and ran would all be grouped together using lemmatization. Previously, I was relying solely on the TF-IDF system for transforming the descriptions into vectors to be used in the LinearSVC classification model. However, I remembered that lemmatization was mentioned in the article that David sent over, so I thought I might try and implement this as part of the text preprocessing before being transformed using TF-IDF to see if it would further increase my accuracy. Ultimately, it seems like it increases the accuracy of my largest 200k dataset by .12% which doesn’t seem like much, but this could amount to hundreds of rows in the long run. It doesn’t seem to positively impact the accuracy of smaller data sets as much, but I think that since Spend data is generally larger data sets, I will keep this lemmatization implementation. I think lemmatization will prove to be a more helpful feature if I am given more data to train my model, since it works better with more training data
                </p>
                <p>
                  Today I also updated Rajiv and Kiran on my project. It seems like accuracy (95-96%) and efficiency (2-3 minutes for 200k rows) of my tool so far is pretty good, so I don’t need to worry too much about researching new ways to increase accuracy and efficiency. They also mentioned that the Business team will likely be most interested in the feature where my model is able to make predictions for the unspecified purchase codes, since this is what they are having the most trouble with. Kiran was also able to take a quick look at the predictions my model was making for the unspecified data and confirm that they were in the correct general categories. I’ll get more feedback on the accuracy of these predictions from the Business team on Wednesday. Rjiv and Kiran also recommended that I start looking into how I might read information from a database instead of an Excel spreadsheet. Rajiv mentioned that Himanshu has experience in this area, so I might reach out to him and ask if he has any recommendations or insight for the best packages or methods for this. Lastly, Kiran recommended that I be prepared to explain some background information on my code and algorithms to the business team on Wednesday so that they understand the process used for categorizing the data.
                </p>
                <p>
                  Tomorrow, I’ll reach out to Himanshu about reading information from databases. I’ll also put together a list of topics I need to cover, questions I have, and demonstrations to prepare for my meeting with the Business team on Wednesday to make sure that I hit all the points that I need to and that I don’t forget any of the questions that have come up. Otherwise, I’m pretty happy with where I am with this tool in terms of presenting an update to the Business team!
                </p>
            </div>
          </div>

          <div id= "July-02-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 2, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Agile Frameworks</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning the scrum meeting was cancelled, so I was able to finish the LinkedIn learning course about servers (that I started yesterday) earlier than expected. Through this course, I have been able to come up with more concrete questions that I can ask Don during our meeting. Unfortunately, something came up during the afternoon for Don, so I rescheduled our meeting for Monday morning. I’m planning to ask questions about what kind of server setup I should consider (Microsoft server?), what role of server I might need (file, hyper-v, document?), and how I can configure an IP address.
                </p>
                <p>
                  For the rest of the morning I worked on increasing the efficiency of my Spend classification tool by saving and loading the model. The original code was both training and writing predictions each time I ran the program. I thought it might be more efficient if I could save the trained model so that only the predictions would need to be calculated on run since the model should be trained the same way each time. There are a couple of ways to save a model, but the two that I researched were pickle and joblib. Ultimately, I decided to go with joblib, since it's better suited for larger arrays. It was pretty straightforward to implement joblib and save the trained model to a new .sav file. There were a couple of steps relating to loading in variables from the training file before being able to make new predictions in a new file, but overall it was a pretty smooth transition. With this implementation, I can train the model once on a large amount of data to get the most accurate results. Then, when needed, the program will have a separate file to write predictions based on the already-trained model more efficiently. I think this should aid with the previous problem with sacrificing accuracy for efficiency or vice versa so that we get the best of both worlds. :) In terms of runtime, the old version of the program took 3:30 minutes to write predictions for 200k rows. The new version takes 1:30 minutes to write these same predictions. This is a pretty significant efficiency boost and hopefully this will make the tool more scalable!
                </p>
                <p>
                  Today I also got to take a virtual tour of FCAT/Innovation Center. I learned about how FCAT works with new emerging technologies and builds tools to help Fidelity associates and customers succeed. There was a lot of emphasis on touchless interaction and VR technology. I’d be interested in exploring some of the areas mentioned during this tour, which seem to be increasing in importance, like cybersecurity and AI. I have some exposure to AI this summer with NLP for Spend classification, but I would be interested in being more immersed with AI and exploring other applications.
                </p>
                <p>
                  For the rest of the afternoon, I learned about different types of Agile frameworks. I found a course yesterday that compared DA (Disciplined Agile) and Spotify Agile and explained which framework might be best suited for different enterprises since Rajiv mentioned how Fidelity is moving toward a Spotify Agile framework. After completing this course, I found another course on the basics of Scrum, which is what my team currently uses. I was able to get through most of the course today and I plan to finish the last piece on Monday. Since Scrum is widely used not only in Fidelity but in many organizations, I’m excited to be able to apply what I’ve learned in the short-term and long-term future.
                </p>
                <p>
                  I have tomorrow off for Independence Day, but I’m excited to come back on Monday and get some feedback from Don about how to use servers and from Kiran about my progress with the Spend tool. I also have my meeting with Nancy on Monday, where I might ask more about FCAT or about how mobility works within Fidelity, especially in tech. Next week I get to show my progress to some of the business team as well, so I’m excited to hear their feedback and move forward!
                </p>
            </div>
          </div>

          <div id= "July-01-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JULY 1, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Learning About Servers</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent a majority of my day today starting to learn some basic information about servers. Since I am meeting with Don tomorrow to discuss the possibility of using a server to allow other associates to use and improve the tool that I have started working on, I wanted to get familiar with some terminology and basic components of servers. I started off with some Youtube videos explaining what a server is and the basic applications of why you might want to use a server. I then moved on to a LinkedIn learning course which was accessible through Fidelity central about managing and administering a server. Today I was able to complete 5/7 of the lessons in the course and I plan to finish the remaining 2 lessons tomorrow before my meeting. Some of the information in the course may not be directly related to my use of a server, but I think it’s still interesting and good information to have.
                </p>
                <p>
                  Today I also had my meeting with Nancy. Most of the time I asked about her academic/career journey that led her to where she is. A lot of the time, when professors or other associates talk about their careers, they have been working for a number of years, so their advice is generally about finding a passion and pursuing it. I think that since Nancy is closer in age to me, a lot of her advice was more directly applicable. She talked about how she had switched majors many times before declaring and how she is still solidifying her career goals. She also recommended some resources for me to look into. In particular she recommended looking into FCAT, which is at the forefront of innovation for Fidelity. I booked a virtual tour for tomorrow afternoon to check out what FCAT does and if this is something I might be interested in applying for next year or doing more research on. 
                </p>
                <p>
                  I also had my 1:1 with Rajiv today, where we discussed my progress with the classification tool. I explained what I had accomplished with increasing the accuracy, printing the outputs, and deciding on an algorithm. I also explained that some feedback on where I am might be useful to making sure I am on the right path. Rajiv recommended that I set up a meeting with him and Kiran for Monday next week to update him and get advice on any last-minute changes and then to set up a meeting with the Business team for early next week. I have set up both meetings and am excited to get some new feedback!
                </p>
                <p>
                  Rajiv also told me a bit more about agile, sprints, and workflow. I learned more about how the pre-planning and planning stages affect the sprint pacing and how new unexpected tasks can affect this. I also learned about spotify agile, which is an up-and-coming methodology similar to the version of agile used within Fidelity. Rajiv recommended that I could look into spotify agile if I have free time, since this seems like a newly popular method. I found a LinkedIn learning course for agile vs spotify agile that I plan to go through if I find that I have free time. :)
                </p>
                <p>
                  I expect tomorrow to be similar to today, where I’ll finish up my course about servers, take my Virtual FCAT tour, meet with Don, and perhaps learn about spotify agile if I have time. Looking forward to learning more about servers and how I might use them!
                </p>
            </div>
          </div>

          <div id= "June-30-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 30, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Parameter Fine-Tuning</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I started my morning with 3 back-to-back meetings with the FPAIT APT team. We started with the usual daily scrum call, where I am  able to follow along but I’m still not familiar with the specifics. I think that unless I get directly involved with the database system it will be difficult for me to understand the ins and outs of the daily scrum calls, but it’s still nice to check and see what the team is up to. Next, there was an end-of-month meeting discussing what was accomplished in June. This gave a broad view of what the team had accomplished during the month and what still needed work in July. One part of the meeting that stuck out to me was at the end of the meeting when we had a couple minutes to “shout out a coworker” which was when team members could praise others for exceptional work. I thought this was a nice way to celebrate team members and to break up an otherwise formal meeting especially because the current remote work environment can make it hard to feel connected to other associates. Lastly, there was a meeting about the current update. After last week’s meeting with Poornima, I had a better understanding of what the update was about and what aspects were being discussed, but again I’m not too familiar with the specifics of the update components.
                </p>
                <p>
                  I spent the remainder of my morning and early afternoon exploring parameters for LinearSVC. Since I decided on LinearSVC as my algorithm of choice for today, I wanted to experiment with changing the default values of the parameters to see if I could improve the accuracy at all. I found that the parameters that maximize output vary depending on the size of the data set. I initially experimented with values for my 2k row data set, but when I applied the same parameters to the total 200k data set, it actually decreased the accuracy. Ultimately, I found that the variables that affect the accuracy of my data are C, fit_intercept, and intercept_scaling. Other variables like tolerance, verbose, and max_iter generally don’t affect the accuracy or the default value consistently produces the most accurate results. Ultimately, changing the parameters didn’t make a huge difference, since it just increased my accuracy from 95% to 96%, but on a larger scale this small percentage change could be a difference of hundreds or thousands of values being correctly categorized. I’m pretty happy with the progress I’ve made for now. :)
                </p>
                <p>
                  This afternoon there was a ‘Lunch and Learn’ panel with Personal Investing and how they’ve been responding to market volatility and Covid-19. Since my project and my team are not directly involved with the markets or investing, it was interesting to learn about a completely different field under the same company. I think I’ll continue to make an effort to attend a variety of ERG events since it seems like a good way to get to know what’s happening in other branches of Fidelity.
                </p>
                <p>
                  Today I also got involved with the Digital Champions program in the intern group, which is designed to help promote engagement, plan events, be a technological leader, and give real-time feedback. There are a couple options for how to get involved, and I think I can realistically commit to the 21-Day challenge which has daily 5-10 minute tasks and the Elite 21-Day challenge which has daily 10-20 minute tasks. The other more intense programs might not be realistic for my current workload, but if I find myself with free time I’ll definitely look into them! There were a couple of quick tasks today about navigating Microsoft Teams and Outlook and I’m excited to see what else is in store.
                </p>
                <p>
                  For the rest of the afternoon, I looked into different methods for vectorizing text. I am currently using TF-IDF (Term Frequency-Inverse Document Frequency) which pulls out the most ‘important’ words for each category in a document based on its frequency of appearance for a category compared to the entire document. I’ve come across other vectorization methods like word2vec and gloVe during my research phase in the first week and in the article that David sent. Ultimately, it seems like TF-IDF works best if you have a large labeled data set (which I do). Word2vec and gloVe are strongly favorable only if you have sparse training data, but when you have >10k rows of training data, TD-IDF outperforms other methods, so I will stick with TF-IDF. I also experimented with TD-IDF's parameters to see if I could further increase the accuracy, but it seems as though the values I have been using are optimal. For now I think I’m done experimenting with parameters to increase accuracy, but I’ll see if Rajiv has further suggestions for how to improve accuracy and/or efficiency tomorrow.
                </p>
                <p>
                  It seems like the end of the month is a busy time for a lot of people! Rajiv rescheduled our meeting for tomorrow morning, so I look forward to updating him on my findings and my progress then. I also have my meeting with Nancy tomorrow, where I’ll ask the questions that I compiled yesterday. Since I’m happy with my progress with my classification tool for now, I plan to spend my time tomorrow looking into servers. I don’t have prior experience setting up or using servers, so I’d like to learn more before my meeting with Don on Thursday so that the meeting is as productive as possible and I can follow along with any suggestions he has without needing to ask for clarification on the more basic terms.
                </p>
            </div>
          </div>

          <div id= "June-29-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 29, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Deciding On LinearSVC</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  This morning, after the scrum meeting I fixed my method of random sampling. Last week, some of the data that I was writing prediction outputs for was duplicated from the training data, which meant that my results were misleadingly high. I fixed my method so that I removed some data randomly using the .sample() and .drop() functions at the beginning before the model was trained to save for testing and writing predictions. This allowed for more realistic results. For a set of 200 rows, the model was about 70% accurate and for a set of all 200k rows, the model was about 95% accurate. This matches the accuracy levels seen last week for Linear SVC when comparing algorithms. There is still quite some work to do for fine-tuning the model to be even more accurate.
                </p>
                <p>
                  There was also a panel with some of the executive leadership at Fidelity to answer questions from interns. We got to hear from Abby Johnson (President and CEO) and members of her senior leadership team on topics like current events, advice to their younger selves, professional growth, business strategies, etc. It seemed like the members of the senior leadership team were pretty close and made conversation and jokes throughout the webinar, which was a pleasant surprise since a lot of the webinars so far have been pretty strictly following a pre-set schedule. A lot of the leadership also mentioned their experience working at companies prior to joining Fidelity and I think that these were often the most insightful topics. A lot of the advice they gave had to do with taking risks and opportunities when possible and not ‘sweating the small stuff’ during college and the beginning of your career. This was nice to hear, especially coming from a group of people who have achieved such great things in their careers. Hearing about leadership roles from this panel definitely got me thinking about more managerial roles and job opportunities in my future.
                </p>
                <p>
                  Today I also got in touch with Don from the System Engineering team about setting up a Fidelity server. I gave him a brief overview of my project and the scalability concerns I was having and asked if he had any insights. However, since setting up a server is a pretty technical matter, he asked to set up a meeting with Rajiv and I to talk through some of the more technical aspects before offering advice or recommendations. It seems like both Rajiv and Don are pretty busy this week, so the first reasonable availability that I could find was for Thursday afternoon. I’m looking forward to working towards some of the next steps and looking into how I might be able to scale my tool. I’ve never worked with servers before, so this is another new field that I can look into this summer.
                </p>
                <p>
                  For the rest of the afternoon I worked more on my code and prepared what I have so far for my 1:1 with Rajiv tomorrow and for the business procurement team at some point in the future if needed. I decided to take down the times for the algorithms that I was initially considering so that I had a clear reason for choosing LinearSVC. I went back to RandomForestClassifier and decided to try some other parameters, since LinearSVC and RF have similar accuracy levels. I remember reading about how having a large number of trees can greatly impact the run time, so I tried RF on the original 200 trees, then cut it to 100, then down to 25. At 25 trees, RF takes about 3:30 minutes to run, which is a lot faster than the original 25 minutes to run at 200 trees. However, this is still considerably slower than LinearSVC which only takes 1:45 minutes to run. I then ran SGDClassifier, which had a comparable runtime to LinearSVC on smaller samples of about 200 rows, but when I increased the sample size it was even slower than LinearSVC. According to quite a few sources, LinearSVC seems to be more suitable to larger scale samples than SGDClassifier. With this analysis done, I feel solid in my choice of LinearSVC for the model’s algorithm in order to maximize both accuracy and efficiency.
                </p>
                <p>
                  I’m still looking into LinearSVC parameters, but I haven’t come up with anything that seems to fit the data that I am using. I may need to rework the structure of my data or keep looking for algorithms to get a meaningful increase in accuracy while maintaining the current level of efficiency. For now, I’m going to keep looking, but reworking the structure of the data is an option that I will keep in mind. I also finally had the opportunity to look into the source that David recommended last week. A lot of the information confirms the choices I have made with SVC and text classification, but it also gave me some new things to think about like using word2vec instead of tf-idf or looking into more deep learning/unsupervised options. I’ll look into these more during my free time and see if I can feasibly work these aspects into my existing structure.
                </p>
                <p>
                  I was scheduled to have my 1:1 with Nancy today, so I compiled some questions about career focus and mobility in tech, but this seems to be a busy week for her, so we’ve rescheduled for Wednesday morning. I also compiled some notes about the broad view of what I’ve accomplished so far, demonstrations of outputs, and further questions for my 1:1 with Rajiv tomorrow. I’ll also continue looking into ways to expand my code using the topics in David’s article or LinearSVC parameters tomorrow. I’m looking forward to meeting with Rajiv to see if he has feedback for next steps I can take.
                </p>
            </div>
          </div>

          <div id= "June-26-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 26, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Ready For Next Steps</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I didn’t have any meetings today, so I was able to focus on my code and gain some insight on where to go next. This morning, I worked on formatting my outputs. I decided to have separate spreadsheets for the ‘UNSPECIFIED’ predicted outputs and comparing the predictions for the randomly sampled defined output to their actual values. I also included some conditional formatting in the defined output page to more easily spot where my predictions did not match the actual values. I decided to run both the ‘UNSPECIFIED’ code and the defined prediction code on 200, 2000, 20k, and the total 200k data set to see how the predictions improved as the data set got larger. It’s a bit hard to make concrete observations on the ‘UNSPECIFIED’ data but it seems like the data is better categorized for a larger data set. However, there are definitely still misclassifications. For example, there are a couple instances where software gets classified as hardware. For the defined outputs, the predictions are definitely better with a larger data set. A data set of 200 is about 93% accurate and a data set of 200k is about 98% accurate. However, with my current method of ‘random sampling’ some of this data is the training data, so the results are misleadingly high. Next week I may look into asking for more data or splitting off a section of the sample data specifically for testing, which would not be included in the training data.
                </p>
                <p>
                  I also captured some visualizations of where the ‘UNSPECIFIED’ predictions were getting categorized. I wanted to see if this matched the distribution of the defined data set to see if the imbalance of the training data set was affecting the predictions. From what I can tell, it doesn’t seem like the imbalance is affecting the predictions too much, but if incorrect predictions into the same categories continue, I will look further into this.
                </p>
                <p>
                  In the afternoon, I worked on improving the accuracy of my code. I looked into the parameters for LinearSVC, but it doesn’t seem like I can feasibly implement a hierarchy system for classifying the data without sacrificing a lot of efficiency. While looking into parameters I stumbled across a method called SGDClassifier, which is for Stochastic Gradient Descent. This uses the same logic as Linear SVMs but using gradient descent to find the optimal parameters. I implemented a version of SGDClassifier using its default parameters and it seems to be almost equally efficient compared to LinearSVC. I’ll need to look more into how I can possibly change the parameters for both LinearSVC and SGDClassifier to improve the accuracy. 
                </p>
                <p>
                  I think that I currently have a pretty efficient and accurate prototype, where it is 95% accurate on a 35,000 row training data set and can make predictions for 200,000 rows in just over 2 minutes. Of course, these can both have room for improvement, but I would like to check in and get some feedback on where I am before pouring time into small accuracy and efficiency changes, in case I need to make any larger adjustments. I might ask Rajiv or Kiran what they think on Monday. Also, since I have the output method set up, I’m wondering if I should prepare to show the business team where I am so far or if I should make more progress regarding scalability before I demo my code to them. I’ll ask Rajiv about this on Monday. Since the machine that Himanshu used to create his server was decommissioned, I needed new resources for setting up a server. After asking Rajiv for additional resources, he directed me to Don, a Systems Engineer. I haven’t had the chance to send out a message to him yet, but I plan to do this first thing Monday morning.
                </p>
                <p>
                  I’m honestly a bit surprised at the progress that I’ve been able to make this week and having great connections like Kiran, Rajiv, David, and Nancy has definitely helped a lot. As I get further into the project, I anticipate that there will be less robust resources and more challenges, since I am still in the initial building phase of the project so far. I’m looking forward to learning more about servers and showing others the progress that I’ve made. :)
                </p>
            </div>
          </div>
          
          <div id= "June-25-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 25, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Writing Outputs</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I’m definitely getting more used to scrum calls :). This morning, I understood a lot more of the terminology and was able to follow along with the general flow of the meeting. However, I am still a bit lost during the more in-depth discussion of certain components. As I listen in to the calls and get more familiar with the components hopefully I will be able to understand more of these in-depth conversations as well, but it’s nice not to feel completely lost anymore.
                </p>
                <p>
                  This morning I worked on choosing an algorithm to stick with. As I mentioned yesterday, I split LinearSVC and RandomForestClassifier into separate documents so that could compare their speeds. LinearSVC is definitively faster than RandomForestClassifier, so I will be using LinearSVC as my algorithm for finding predictions from now on. I also captured the images of data visualizations from yesterday’s code in case I want to view them or display them during meetings so that I don’t have to re-run my code. It’s actually pretty astounding looking at the graphs and seeing how much of the sample data is unspecified! (~70%).
                </p>
                <p>
                  In the afternoon there was a 2 hour workshop about the economics of Fidelity. This workshop was meant especially for interns to learn more about the inner financial workings of how Fidelity operates. Some of the content was familiar from the Financial Economics and Macroeconomics courses that I took in school, but there was also a lot to learn. Especially interesting to me was seeing how the concepts that I learned in Economics classes were applicable to running a business and investing in different assets. My particular project isn’t really involved with investing, but I think that it’s important to know how other parts of Fidelity work even if I am not directly involved in them.
                </p>
                <p>
                  For the rest of the day, I worked on how to write output predictions into Excel. This process was a bit frustrating, since I found that a lot of sources were outdated or certain functions were no longer functional. Eventually, after quite a lot of trial and error, I was able to successfully get my predictions correctly formatted into an Excel sheet. I first thought it would be interesting to make predictions for the ‘UNSPECIFIED’ items, since these items were cleaned out from the original data. Since these items were previously classified as ‘UNSPECIFIED’ I don’t have a way to cross-reference and make sure that these items have been put into the correct category. When I looked at the data, it seemed like most of the categorizations were not wildly inaccurate. However, since I have only been working with this data for about 2 weeks, I don’t have the intuition for where the data should really be classified, so I will check with Kiran or the Business team. During Tuesday’s meeting with Rajiv and Kiran, they mentioned that it might be good to print out the actual vs. the predicted test data, so I spent a little while tweaking my code to have this functionality. Looking at this data, it seems like my code does a pretty good job, but there are some instances where the categorization is completely different than what it should be. I will need to brainstorm and research ways to fix this issue. Currently, I am thinking about a hierarchy or weighting, since some categories are more relevant to classification than others. But I am not sure how feasible this method would be with the algorithm I am using.
                </p>
                <p>
                  Tomorrow, I have almost no meetings! I plan to look into improving the accuracy of my classification tool as mentioned above. Today I spent a lot of time getting my code to function, but I have a lot of random variables or irrelevant comments floating around, so I will also spend some time cleaning up my code and making it more readable tomorrow. If I have time or if I get stuck, I might also start googling or asking around about setting up a Fidelity server and making my tool scalable like Rajiv mentioned. If possible, I will look into getting my code to be more efficient, but after today, I think some of the speed issues were from running so many models at once, so it may not be as big of an issue as I originally thought.
                </p>
            </div>
          </div>

          <div id= "June-24-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 24, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>More Accurate But Less Accurate</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I signed on a bit earlier this morning and got in touch with Himanshu. He told me that he used to have the Fidelity local set up, but it is currently decommissioned since the machine they were running it on got decommissioned. This is unfortunate, but I think that further down the line, when I have a better prototype, I can look into more resources and see if there are viable options about Fidelity servers. Perhaps I can reach out to my mentor group, especially since Nancy has added more developers to the chat! Himanshu also suggested that I use Spyder instead of Jupyter within the Anaconda suite, since Spyder is better suited for sunning scripts and applications and is more GUI centric so it would be better for my classification tool.
                </p>
                <p>
                  I sat in on the scrum call this morning and things were a lot clearer after talking to Rajiv and Poornima yesterday! I still don’t understand the details of what is being discussed, but I can follow along and get a general idea of what the conversations are about. I heard a few new terms, but I was able to google them after the meeting and answer those questions.
                </p>
                <p>
                  For the rest of the morning and early afternoon, I worked on transferring my code from Jupyter to Spyder. This went pretty smoothly, since they both run Python. I also ran my code on a larger sample size of 20,000 rows. This was pretty slow to run even after I removed some of the graphics being created. Something I will work on tomorrow is creating separate files for running the Linear SVC and the RandomForestClassifier algorithms so that I can evaluate if either of these algorithms is significantly faster than the other. My current code runs all 4 algorithms (Linear SVC, MultinomialNB, Logistic Regression, RandomForestClassifier) in one file, which could be what is making the program so slow. In larger data sets, Linear SVC and RandomForestClassifier are pretty close in accuracy, so if there is a large discrepancy between the algorithms in speed then this will be the determining factor in which algorithm I ultimately choose to run with. The results of running my program on 20,000 rows is promising! I got up to about 97% accuracy, which I am very happy with. :) However, the code for 20,000 rows takes about 6 minutes to run, which I am not happy about. :( 
                </p>
                <p>
                  When examining the graphics for the 20,000 row data set, I noticed that a very large proportion (about 60%) of the data is classified as ‘UNSPECIFIED’ which could throw off the data by a significant amount. I added a few lines of code to filter out all the data which was ‘UNSPECIFIED’ in order to get more representative results. Doing this cleaning brought the accuracy for 20,000 rows down from 97% to 93%. While the accuracy is technically lower, the previous version 97% accurate tool was ‘classifying’ some data as ‘UNSPECIFIED’ which is not very helpful for a classifying tool. So even if the accuracy score is technically lower, the fact that data is actually being classified correctly 93% is still great for now! For fun, I tried running my code on the total 200,000 row sample set. This took a very long time to run (40+ minutes), but I was curious to see how much data was actually unclassified and how accurate I could get. It turns out that out of about 200,000 rows, about 150,000 rows were ‘UNSPECIFIED’ which was really surprising. I was able to get an accuracy level of about 95%. While I was waiting for my code to run, I looked up some more in-depth information about some of the pieces being used within the program such as TF-IDF (Term Frequency, Inverse Document Frequency) vectorization for turning text into vectors to feed into the algorithms and more information on algorithms like Logistic Regression that I am not as familiar with. I added some comments to my code as well and fixed up the formatting.
                </p>
                <p>
                  This afternoon, I also attended a WLG (Women’s Leadership Group) Q&A with Eric Bocan, an Executive Sponsor for the Westlake location’s WLG. He discussed mobility, mentorship, and returning to the office. This wasn’t an event targeted toward interns so it was really interesting to be able to hear his advice for full-time employees and gave me some things to think about for longer-term career goals.
                </p>
                <p>
                  Tomorrow, I will continue working on my code. Specifically, I will split the LinearSVC and RandomForestClassifier algorithms into separate documents so I can evaluate their speeds separately. I will also look more into writing my predictions into an output document. The problem I am running into is that the current method for making predictions doesn't preserve the ids of the objects, so it is hard to map the prediction to the correct row and id in the spreadsheet.
                </p>
            </div>
          </div>

          <div id= "June-23-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 23, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Things Are Starting To Make Sense</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent most of my day today in and out of meetings. This was kind of a nice change from last week, where I spent most of my time doing individual research. I didn’t make too much progress with my preliminary version of the NLP classification tool, but I got to know what the APT team was working on in a lot more depth, so I still had a full day of learning. I started my morning again with the Scrum call, then almost immediately after had a meeting about an update program. I wasn’t too sure what was going on in these calls since there were a lot of unfamiliar terms and acronyms being thrown around. Since I was confused, I reached out to Poornima to ask if she had time in her schedule for me to ask her some questions about what she was working on, clarify some terms, and give an overview of the workflow.
                </p>
                <p>
                  Rajiv and I also had our weekly 1:1 this morning. He explained more about the inner workings of how Fidelity uses databases and applications of how databases. I think this explanation put into perspective some of the tools that are being discussed in APT meetings. Rajiv even showed some real-time code examples, which was really nice especially since I don’t have experience with databases or SQL. I was able to demo what I worked on yesterday with my 75% accurate tool that compares a few NLP algorithms on the test data set of 200 rows. Rajiv suggested that I show Kiran what I have accomplished so far so I can get some feedback and ask questions, so he set up a meeting for the afternoon.
                </p>
                <p>
                  I had my meeting with Poornima this afternoon. She gave a very comprehensive overview of the Jira workflow and the APT production calendar. She also explained what happens at each stage of the project from start to finish (To-Do, Design, Development, User Acceptance Testing, Pending Migration, Certified), which will help me follow along with understanding the scrum calls. I also asked some questions about some terms and acronyms that I heard but did not understand. A lot of these terms have to do with SQL databases, so I will look more into the terminology on my own time as they come up. Poornima answered a lot of my existing questions about terminology though. I was especially confused about what dependencies, packages, modules, decommissioning, retiring, and schemas were in the context of the team, but it’s much clearer now! Poornima mentioned that when she first joined Fidelity, these terms were also very new to her and how it was almost like picking up a new language. This made me feel a lot better about being lost and asking so many questions and encouraged me that I might be able to understand the meetings by the end of the summer.
                </p>
                <p>
                  My last meeting today was demo-ing my tool for Kiran and Rajiv. Kiran and Rajiv seem happy with the progress I have made so far and it was nice to get some feedback after working on it mostly alone for the last few days. Some of the feedback mentioned from the meeting was that I might need to look into using a Fidelity local server. Currently I am running my code in Jupyter notebooks as part of the Anaconda suite, but it would be a lot more secure and a lot easier to implement company-wise if I was able to set up a local server. Since I don’t have prior experience with local servers, Rajiv suggested that I reach out to Himanshu, since he implemented a local server for his NLP tool. Further down the line, I would also like to ask Himanshu if he has time to take a look at my tool and give me some feedback based on his NLP expertise, since I am new to NLP and may not be doing things in the most efficient way. Lastly, Kiran suggested that I put my predictions into a formatted spreadsheet before showing it to the business side so that it is more of a finished prototype and we can really see how the tool would look in action. These suggestions are all things I plan to get started on tomorrow.
                </p>
                <p>
                  In between meetings I made some small tweaks to my tool in an effort to improve accuracy. I tried adding additional spreadsheet information so that I am training my tool on information from 5 different columns instead of just 3. This improved the accuracy from about 75% to 80%, which was exciting! I also tried running my data on a 2,000 row data set instead of the 200 row data set that I was initially using. This brought the accuracy up to 88%! :) However, I noticed that when I made the jump from 2000 rows from 200 rows, my program was noticeably slower. Efficiency is definitely something I will have to work on improving before I try to run this model on the large amount of data used in Spend (~200,000 rows). These initial improvements in accuracy is very exciting, but I anticipate that fine-tuning the model is going to take a lot more time and research than just adding information. I anticipate having to look into the algorithm’s inner workings and parameters to do this fine-tuning.
                </p>
                <p>
                  Tomorrow I don’t have many meetings, so I can work more on my code. I still have the warnings about ‘minimum split size’ that I was working with and it seems like this is coming from the fact that my data is relatively imbalanced and some categories have very few data members. I’m not yet sure how to address this issue without just feeding my model more robust training data. I’ll also try to wake up earlier so I can reach Himanshu and ask for his advice on local servers. I’m eager to see if I can understand more of tomorrow’s scrum call now that Poornima and Rajiv have filled me in on some of the high-level concepts and terminology.
                </p>
            </div>
          </div>

          <div id= "June-22-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 22, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Somewhat Functioning First Attempt</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I started off my morning by joining the Scrum call again. I think I’m getting a better idea of what is happening now that I have been attending calls for about a week. Honestly, I’m still pretty lost, especially since my project is a bit disconnected from the database work that they are discussing. I think that if tomorrow’s scrum call is still just as confusing, I will reach out to Poornima and meet with her to ask questions about what the team is working on and what she is working on. Hopefully, this will give me more insight into what the scrum calls are about so that I can follow the calls more closely.
                </p>
                <p>
                  For most of the morning, I was trying to download nltk packages. The nltk library is quite large, so it took over an hour to completely download once I passed the right authentifications. While I was waiting during this time, I watched some videos about neural networks. I understand a bit more about hidden layers and activation functions. The downloads finished before I completed the videos, but I have bookmarked them so that I can watch them if I am waiting around or if I need a break from writing code. :) The Fidelity mentor chat was also pretty active this morning, so I talked to Jenna, Benjamin, Anushka, and some of the people Nancy added on Friday. Kaitlin added her mentee, Chelsea, so it was nice to meet someone new. Someone from the CTG interns made a group chat, so I’m hoping to get to know some interns within my business unit beyond just the introductions we had on Tuesday.
                </p>
                <p>
                  Once the nltk packages finished downloading, I tried getting to work using the libraries. I found a tutorial for using SVM and Naive Bayes on text classification instead of on numbers, which fixed the problem that I was having on Friday with using strings instead of floats. However, this tutorial was not accurate at all when applied to my data. SVM was only about 3% accurate and NB was about 3.5% accurate. I messed around with some parameters to try and see if I could get it working more accurately, but did not have much success.
                </p>
                <p>
                  I took a break from coding and talked to Nancy for a little bit about internships, college, and studying abroad. Since I noticed that a lot of people on my team are male, I wanted to ask Nancy about her experience in tech at Fidelity with the gender ratio. She mentioned that while there are more men than women overall, the ratio depends a lot on which team you are on. She mentioned that she was on a team where all the leadership was women and she mentioned that her LEAP class was pretty evenly distributed between men and women. This was reassuring to me and I think I just happen to be in groups that are more male-dominated. For example, our CTG intern group has about 20 people, but just 5-6 out of the 20 are women. The people that I have been in contact with on my team are also primarily male, with the exception of Janice and Poornima. WISTEM also has an event next week, but unfortunately this conflicts with a meeting. I’m looking forward to talking to Nancy more in the coming weeks and getting her advice on the internship and beyond. :)
                </p>
                <p>
                  Later in the afternoon, I found a different tutorial for Text classification, which used SVM, NB, RF, and logistic regression. This method took a while for me to implement since my data has more moving parts than the sample data. It ended up being worth it, since it’s much more accurate than the tutorial I was working with this morning! Each method is about 60-75% accurate. Of course, I will need to work on getting the model to be much more accurate before the Business group can use it since even 75% accuracy isn’t exactly reliable, but this is a good starting point compared to 3%! This tutorial has a lot more ways to visualize the data, which made the models seem much less ‘black box’ and made it a lot easier for me to see what was going on behind the code. The data set that David sent me last week has about 200,000 rows, but I am starting with 200 rows so that it's more manageable as I work through initial bugs and formatting, but the size of the data is something I will keep in mind as I move forward. There are still some changes I need to make to the tutorial’s parameters in order to fit my data. This is because the data I am working with has a lot of different categories and sometimes categories in the test data are not present in the training data, which means the model doesn’t know what to do with them. The large number of categories also makes the data visualization tools a bit difficult to read, so I may spend some time seeing if I can improve readability. There are some other warnings that I need to work through regarding ‘minimum split size’, but I’m not sure exactly what this means, so this is an area that I need to research more tomorrow as well.
                </p>
                <p>
                  Tomorrow I have my 1:1 with Rajiv, so I plan to update him on what I have been able to accomplish up to this point and what I hope to do next. I will also reach out to Poornima tomorrow so I have a better idea of what’s going on during the scrum meetings and so I can finally meet her face-to-face. I should have reached out to her sooner, but all the new information last week was a bit overwhelming so it totally slipped my mind. In terms of the text classification tool, I plan to address the warnings and research (and maybe even implement?) ways that I can improve accuracy.
                </p>
            </div>
          </div>

          <div id= "June-19-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 19, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>Finally Coding</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I finished up my preliminary stage of research. This morning I got in contact with Himanshu and expressed my concerns about SVM working best only with small data sets. He said that SVM should be able to work with the size of the dataset that I am working with, but since I mentioned that I was looking into other algorithms, he recommended that I double check on the accuracy of those algorithms before implementing. Based on accuracy, I think that Random Forest would be preferable to Naive Bayes. However, since he mentioned that SVM still seems feasible, I will try SVM first. If I run into issues with SVM and the large data set, I will keep Random Forest (RF) in mind as a backup option. Since I had a plan for which algorithms I wanted to use, I tried to start coding at the end of the morning, but got stuck since I kept running into HTTP errors when installing Python packages through Anaconda.
                </p>
                <p>
                  In the afternoon, I had a bit of a break from coding and research. I attended the Fidtern meetup just like last week. It still felt a bit stilted since we mostly just introduced ourselves and talked about work, but it was good to see some familiar faces. I also had a short conversation with Korey from University Talent about my internship experience, especially since the internship is virtual this year. Around this time Nancy (my FYPN mentor) introduced us to some other software engineers (Gabriel, Hannah, and Kaitlin) as additional resources and connections. I really enjoyed connecting with more young full-time employees in the setting of a group, since I find it much easier to keep conversation flowing in a group with less pressure put on each individual person. Nancy set up a fun escape room activity with Anushka, Jenna, Benjamin, Kaitlin, herself, and I. We solved puzzles together virtually and I thought it was a cool interactive way to bond. :) At the end of the call, when we were talking about ‘highs and lows’ of our week, I mentioned that I was having trouble installing packages. Nancy connected me with a Senior software developer, Josh, on her team to help me out. Within about 10 minutes he was able to help me fix my issue and request elevated access so I wouldn’t have to worry about these problems in the future! It was really nice to get such personal and immediate help from a senior developer. I think this experience has encouraged me to reach out earlier when I run into issues. I was struggling for over an hour with this issue, but Josh and Nancy were able to help me fix it within 10 minutes!
                </p>
                <p>
                  With this problem fixed, I got into writing code in Jupyter notebooks. I learned how to read data from Excel to Python and how to explore some features of the data using built-in functions. I then tried to run this data through the SVM model. It took me a while to understand what the different pieces were doing, but I learned a lot through the process. However, I got stuck, since the data I am working with is not numerical. My data is categorized based on strings, whereas all of the SVM examples that I have found online are using floats, so I will have to find some workaround. I tried using RF as well, since I thought that RF would be less reliant on floats and it might be easier to make alterations to get it to work with my strings, but so far I have not had much success.
                </p>
                <p>
                  Poornima also reached out to me to check in and see how my first week was going. Rajiv has paired me with Poornima if I have questions and Rajiv is not available since Poornima is relatively new to Fidelity and so I might be able to relate to her experiences more. This week I have not had too many issues, since I have been mostly independently learning about NLP and ML concepts. I think that I get further into coding, I will probably be reaching out to her more as I run into questions.
                </p>
                <p>
                  Next week, I hope to continue working on getting either the SVM or RF model (or both?)  working on my small test set of data. If I can get this working, then I can see what happens to the accuracy as I apply it on a larger scale and make some alterations from there. This first week has been pretty fun and I’ve learned a lot of new information. I’m looking forward to taking the weekend to process the new information and experiences and hopefully next week I’ll be doing more coding and continue making connections!
                </p>
            </div>
          </div>

          <div id= "June-18-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 18, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>Exploring Algorithms</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today was a bit of a roller coaster when it comes to where my research has taken me. I spent my morning learning about the Support Vector Machines (SVM) algorithm that Himanshu mentioned yesterday. A brief summary of what I learned is that SVMs plot data into an N-dimensional space, then the algorithm creates a hyperplane that categorizes the data appropriately. This is a very popular ML supervised algorithm and is preferred to a lot of other classification models because of the kernel function, which can map the data to higher dimensions in order to better fit the data if the initial dimensions don’t allow for the data to be categorized well enough by the existing Support Vector Classifiers. I followed a toy example for using SVMs to classify if a recipe was for cupcakes, muffins, or scones based on the percentage of butter and sugar in the recipe. (Apparently cupcakes have pretty high amounts of both butter and sugar, muffins have low amounts of both, and scones have a lot of butter but not a lot of sugar). 
                </p>
                <p>
                  The SVM algorithm seemed to have a lot of promising qualities, especially since it was not too computationally or memory expensive and had high accuracy. However, upon reading more detailed documentation and articles,  quite a few sources mentioned that it works best with smaller data sets. From what I understand, the data I am working on does not seem to be a small data set, so I'm not sure if SVM is the best algorithm. I looked into other algorithms used for classification. The two that seem most promising are Naive Bayes and Random Forest. (Other algorithms like Tree Decision and K-Nearest Neighbors don’t seem right for this project based on incompatibility with accuracy or categorical data).
                </p>
                <p>
                  Naive Bayes has the pros of requiring less computational power, accurately working on large datasets, being fast, being pretty easy to implement (supposedly), and being best suited for text classification so it could be used for the sentiment analysis application that David mentioned last time. However, some tradeoffs are that it makes the strong assumption about the features to be independent and implements zero frequency, which means if the category of any categorical variable is not seen in training data set then model assigns a zero probability to that category and then a prediction cannot be made, so might not be able to fulfill the 'flexible and dynamic' part. Random Forest has the pros of having high accuracy, flexibility, and less variance. Also it’s supposedly not too difficult to implement, works well in handling missing values and detecting outliers, and can identify the most important feature among available features (not sure how relevant this is for the current project). However, it has high computational and memory cost. Additionally, as the number of trees increases, the algorithm can be slow. So, it's not necessarily a problem if the data set itself is large (i.e. a lot of rows in the spreadsheet), but it could be a problem if there are a lot of categories to classify the data into. I’ll ask about the order of magnitude of categories tomorrow!
                </p>
                <p>
                  I spent a little bit more time looking at Deep Learning concepts, but I think my priority is learning these categorization algorithms for now. Tomorrow, I plan to ‘get to work’ earlier in the morning so I can ask Himanshu what his opinion is for SMV if my data set is of a larger scale or if he has additional suggestions for algorithms that I should look into.
                </p>
                <p>
                  This morning, I also had a short meeting with Janice who is the Vice President of IT Management. We talked about my goals for this internship and she gave me a lot of advice and insight about Fidelity as a place to consider working full time. She emphasized how Fidelity cares for its employees through benefits, a flexible environment, and lots of opportunities for mobility within the company. She suggested some ways to get more involved with the culture as well. This has definitely given me a lot to think about when considering if I’ll consider Fidelity as a future employer! :)
                </p>
                <p>
                  I sent an email to David, Cameron, Daniel, Anuj, Kiran, and Rajiv about the current rule-based system for classifying data, so hopefully I’ll get a response tomorrow to clarify those questions and help me find the best suited algorithm for this project! I also have a check-in with Korey from University Talent to talk about how the internship is going so far, so it’ll be nice to catch up with her. I plan to spend tomorrow looking more into Random Forest and Naive Bayes from some different sources. I keep seeing Principal Component Analysis (PCA) mentioned as an algorithm for data analysis and predictions, so I plan to look into if that’s another feasible algorithm tomorrow. Another full day of research and learning new things ahead!
                </p>
            </div>
          </div>

          <div id= "June-17-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 17, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Old and New Directions</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I started my morning off by joining the Scrum Meeting as Rajiv suggested yesterday. After what Rajiv explained to me on Monday, I understand a bit more of what is happening at a conceptual level with the way that the Agile method works and Sprints and the daily updates. However, I am still quite lost when it comes to the actual tools and modules being discussed. I’m sure that as time goes on and I attend more of these meetings it will become less confusing. For now, I will try and keep attending these meetings to become more familiar with the workflow within Fidelity.
                </p>
                <p>
                  Later in the morning, I met with Himanshu and Rajiv to talk about my project. Himanshu is part of the team in India, and he has worked with NLP in the past, so he was able to offer a lot of guidance and helpful information when it came to pointing me in a more focused direction for my research. In particular, he suggested that I check out the Support Vector Machines (SVM) library, since this library is often used for categorization. He also advised that I will probably need to use custom logic for the machine to be able to process Fidelity specific data since pre-existing data sets like NLTK might not be specific enough to cover the vocabulary used in Spend. We talked a little about unsupervised and supervised learning, since it seems that the Business team wants a model that uses unsupervised learning for their flexible and dynamic model. Since Himanshu is in India, my work hours are late into the night for him. To communicate with him in real time, I’ll wake up about an hour earlier, otherwise he suggested that I leave messages for him at the end of my work day and he will respond to them in his morning hours. I’m looking forward to hearing more about the insights he gained from his NLP project in the future and applying it to my own project!
                </p>
                <p>
                  I finished the introductory neural network course that I started yesterday during the rest of the morning and into the early afternoon. I think this course is a good starting point, but if I were to implement deep learning, I anticipate that I would need to find more resources about how to utilize the neural networks and other deep learning concepts that were mentioned in the tutorial.
                </p>
                <p>
                  After lunch, there was a Fidtern workshop about personal branding. I thought this workshop was pretty interesting. Although the workshop covered a lot of material that I had already learned from Mudd’s career workshops, it was interesting to hear it from another viewpoint. I noticed that there was an emphasis on soft skills during this workshop, which is something I can work on displaying more in interviews and on my resume. Around this time I also had some conversations about TV and movies with my fellow interns from FYPN. It seems that as we all get busier, people have less time to talk, but I hope that we can still keep up these conversations in whatever free time we find!
                </p>
                <p>
                  For the remainder of the work day, I started the Stanford NLP and Deep Learning course and started looking into the SVM library that Himanshu recommended. While the Stanford course is very informative, I think that it goes more into the math behind the tools than I am looking for. As ChunLei mentioned earlier this week, my focus for this project shouldn’t be on the algorithms portion of Machine Learning, but rather how these ML algorithms are applied. Of course, to apply the algorithms, I should understand how they work to some extent, but since the Stanford course seems to focus more on the inner workings of the algorithms than the applications, I don’t think I will be continuing with the Stanford course since it doesn;t align with my goals. I also started looking into the documentation for SVM, and I think I understand the basic ideas. Tomorrow I will dive deeper into fully understanding the library. SVM seems much more suited to my project than the NER library that I found earlier this week since it focuses more on categorization based on word semantics than categorization based on sentence structure. :)
                </p>
                <p>
                  I also started installing the necessary tools for starting to write some code, but didn’t have time to finish setting it up, so I will continue to do this tomorrow. I’m not familiar with the Fidelity systems and what restrictions there are on downloads, so I’m trying to take this part slowly and carefully to avoid running into trouble later. Tomorrow, in addition to more research and installations, I also have my meeting with Janice to look forward to.
                </p>
            </div>
          </div>

          <div id= "June-16-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 16, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Networking: Neural and Otherwise</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today I spent more time collecting resources and learning about NLP. In particular, today I started looking at resources about Neural Networks. I found an introductory Neural Networks tutorial on Youtube, which requires no prior knowledge. I started working through this course and plan to use this as my jumping-off point before diving into more advanced resources. I found other courses and articles about Neural Networks and NLP. In particular, I found entire courses from Stanford, one of which is about NLP specifically and another which is specifically about NLP with Deep Learning. I think that once I finish the introductory neural network course I will try the Stanford NLP with Deep Learning course, and if it is still too advanced to follow and I will go back to more basic courses. I also found a few more resources about NER. In particular, I started looking into the documentation for spaCy. I only have a basic overview, so I will go back later and read more of the details when it comes time to start building the tool.
                </p>
                <p>
                  Today I also looked into some possible packages that I might use in the process of pre-processing the text,, such as BeautifulSoup and NLTK. I looked at the capabilities of these tools and how I might use them in practice. In the coming days, I will look into more packages for feature extraction and classification, since I anticipate that this will be the bulk of the work when it comes to being able to accurately classify the Spend data. In the past two days there has definitely been an overwhelming amount of new information, but writing it down here and trying to absorb it little by little has definitely been helping. :)
                </p>
                <p>
                  Today I also got to contact a few different groups of people. So while I am doing quite a bit of individual research, I am still able to reach out to Rajiv and other team members as well as other interns.
                </p>
                <p>
                  This morning Rajiv and I had our first weekly 1:1. During this time, I got to talk about my personal career aspirations and what I was hoping to gain from the internship. I talked about my experience working with front-end and back-end and how I was interested in ML and AI, but there didn’t seem to be many opportunities in ML for undergraduates. Rajiv offered some helpful insight about how fast the CS industry moves and how in 2 years when I graduate, ML might be much more prevalent and how job opportunities could very well open up for undergraduates like me. Rajiv also taught me about Cloud products, specifically SAS, and how they are integrated into Fidelity as well as our everyday lives. I enjoy learning about current relevant technologies used by Fidelity during these meetings with Rajiv. He also suggested that I come to more Scrum meetings so that I can learn more about the corporate workflow, specifically with Agile. I will definitely take him up on that offer and I plan to attend tomorrow’s Scrum meeting!
                </p>
                <p>
                  This afternoon, we had a meet-up with CTG leadership and interns. The meeting was pretty casual, and we went around introducing ourselves and having some conversations about the COVID-19 situation. It was nice to be able to meet the other interns that I might have been working alongside or even sharing office space with in Westlake. I connected with some interns on LinkedIn after the meeting and one intern reached out to me and we had a brief conversation about our projects. It’s cool to hear about other interns’ projects and have the “water cooler conversations” that we might have had back in the office. I also kept in touch with my mentor group throughout the day.
                </p>
                <p>
                  A couple of questions came up during my research from yesterday and this morning, so I messaged all the members of yesterday’s meeting. David responded very promptly and answered a lot of my questions and even gave me some sample data to look at! At first glance, the data is pretty overwhelming. I don’t fully understand it yet, but I will take a better look at it once I get more involved with the specifics of the project. Rajiv also informed me that Janice invited me to Thursday’s FPAIT staff meeting, where I will introduce myself. I have yet to receive the email invite, but I am looking forward to meeting even more people!
                </p>
                <p>
                  Tomorrow I plan to continue my introductory neural network course and hopefully start the Stanford course. Additionally, Rajiv has set up a meeting for me to introduce myself to a member of the team from India after the morning Scrum meeting, which I am excited about. There is also a Fidtern workshop about professional branding that I hope to attend in the afternoon. Looking forward to another busy day of learning!
                </p>
            </div>
          </div>

          <div id= "June-15-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 15, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Monday</p>
                </div>
                <div class="post-title">
                    <p>Focusing My Research</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I spent most of my time today independently researching the more basic concepts of NLP. and the general workflow of data science. I found a particularly helpful video was this video from PyOhio about NLP in Python. The speaker was Alice Zhao and I found that the way she explained the concepts was very clear and approachable for someone like me who is new to NLP and Data Analytics as a whole. I spent most of my morning watching this lecture and taking some notes to come back to later. From this video I gained a basic understanding of the process of NLP and the kinds of insights that can be drawn, but I also found that there were some topics that I was interested in looking further into. For example, I would like to look more into using Pandas, python packages, and stemming.
                </p>
                <p>
                  In the early afternoon, I also looked into other resources, such as the ones that ChunLei sent me on Friday. I looked into resources like Vik’s Blog, towards data science, and sentdex. These resources brought up some very interesting concepts that I had not seen before, and which I will definitely need to look more into. From Vik’s Blog, I think I will research more about Linear Regression, since this is a concept that has come up in my Scientific Computing course, but I would need to do more research to see how exactly it is being applied to NLP and this project. From toward data science, I am interested in doing more research about what tool might be best suited for this project. I know that Python was mentioned before, but it may also be worth looking into R and TensorFlow. I also learned about the difference between the classical ML model and Deep Learning. Classical ML is where you train the model using feature extraction on the input and then classification on the extracted features. Deep Learning is where the feature extraction and classification happen together in one step using neural networks. From sentdex, I will definitely look more into NLTK, since it seems to have some extremely useful built-in tools. 
                </p>
                <p>
                  ChunLei directed me to a site called Amazon SageMaker. He recommended that I not worry too much about the math and the details of the project, but rather get a better understanding of high level concepts. After reading through the documentation, I found that one particular feature that might be useful for this project is Named Entity Recognition or NER. This feature sifts through text data to locate phrases and categorize them into labels like person, organization, or brand. I think that this labelling could be extremely useful for Spend Categorization. However, one problem is that based on the resources that I have seen so far, it seems that NER is used in sentences, whereas I am not sure what form our data will look like. Another problem is that NER categorizes sequences based on predefined labels, which would not be cohesive with the desire for a more dynamic model. NER is definitely a topic that I will spend time researching more.
                </p>
                <p>
                  Later, I had a meeting with Rahiv, Kiran, Cameron, and some new faces including Daniel and David from Business, and Anuj from Kiran’s team. We talked more about the expectations of this project and the pacing. David offered some insight about stemming vs. lemmatization, and suggested that lemmatization might be more accurate. I agree with him and would definitely implement this approach when it comes to that point in the project. I asked some questions about if previous projects have used classical ML or deep learning, but it seemed that the decision of which is best suited for this project will be left up to me. We ran out of time during this meeting since there was a lot to discuss, but I am looking forward to sharing more about what I have learned and asking more questions in the future.
                </p>
                <p>
                  At the end of the workday, I started looking more into classical ML vs Deep Learning. It seems like classical ML is much more approachable and may be easier to implement, but Deep Learning will probably do a better job of accomplishing the dynamic and self-learning model that Business is asking for. I need to do more research about Deep Learning and specifically Neural Networks to see if this is something that I would realistically be able to learn and get started on during the summer. The best and most efficient ways are always the hardest to implement :,). 
                </p>
                <p>
                  Unrelated to work, I found out that I have some connections to other Fidterns! An intern in my mentor group, Benjamin, knows a friend from high school, and another SWE Fidtern, Cassie, knows one of my friends from Mudd! Additionally, I’ve continued talking to my mentor group, and today Nancy added a new member, Jenna, who shared pictures of her adorable dog. :)
                </p>
                <p>
                  Tomorrow, I plan to start looking into some of the topics that I came across today, particularly classical ML vs Deep Learning, Neural Networks, NER, Automatic Feature Extraction, and word2vec. I don’t anticipate that I will be able to get to all of these topics tomorrow, but it’s a starting point into more research! Tomorrow there is also a CTG intern meet-up in the afternoon, where I’m looking forward to meeting other interns in my business unit. 
                </p>
            </div>
          </div>

          <div id= "June-12-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 12, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Friday</p>
                </div>
                <div class="post-title">
                    <p>The More I Learn, The More Questions I Have</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today was the last day of webinars! It was nice to learn so much during training, but honestly, I think I’m ready for a change of pace. Sitting through long Zoom meetings is getting quite exhausting and I’m looking forward to learning more technical skills through projects. This morning we had a pretty information-heavy webinar about HR and specifically about the protocol for logging the hours we work. Then in the early afternoon we played some fun icebreaker games. At noon we had an intern meet-and-greet session where I got to know some interns from Massachusetts and New Hampshire.
                </p>
                <p>
                  I had a meeting with Kiran today to update him on what Cameron and I talked about yesterday. Kiran was able to provide me with a lot more detail about the project’s current status and what my role on the project might be. He also put me in contact with an NLP specialist, ChunLei. ChunLei was able to explain a lot of insight about NLP and how it would play into what the Business team was asking for. ChunLei also pointed me to some really great introductory resources that I was able to get started with.
                </p>
                <p>
                  For the rest of the afternoon, I looked into the resources ChunLei recommended as well as some resources that I found on my own during my online research. I have learned a lot of introductory material about topics like NLP, Deep Learning, Tokenizing, etc. In the coming week or so, I anticipate that I will be spending a lot of time self-studying these topics and getting more familiar with NLP at a high conceptual level. I have found that the more I learn about these topics, the more questions I have for the Business team regarding what they expect for their new Spend tool. For example, I am wondering what kind of data I will specifically be working with and how I might access the data if it is from 3rd party sources. I am also wondering about the new categorization aspect. What would necessitate new categorization? How specific would the categorizations be? How generally can we lump items together? Lastly, I would wonder if there is a strong preference for Python because of previous infrastructure or ease of implementation into the existing tools or if this preference is due to the existing packages? I will definitely try and ask these questions in Monday’s meeting with the Business team and with Kiran.
                </p>
                <p>
                  Throughout the day, I also remained in contact with my mentor group, which was a lot of fun! Next week, I hope to keep in contact with the interns I have met this week and to keep learning about new topics like NLP. I am still getting used to the corporate structure and making sure that I am on top of my meetings.
                </p>
            </div>
          </div>

          <div id= "June-11-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 11, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Thursday</p>
                </div>
                <div class="post-title">
                    <p>A Potential Project!</p>
                </div>
            </div>
            <div class="post-body">
              <p>
                This morning, like the 3 mornings before, consisted of more webinars. Today we learned about strategies we can use to make the most of our internships, like making connections and getting involved in different groups. Later, we heard from FYPN (Fidelity Young Professionals Network) and some details about the mentorship program. Coincidentally, my mentor reached out to me today and I got to meet her for the first time (more on that later).
              </p>
              <p>
                In the afternoon, I had my meeting with Cameron from Procurement Business Analytics. Unfortunately, Daniel had a last-minute conflict and could not make it to the meeting. I got to introduce myself to Cameron and hear about the project that I might be able to get involved with. From his explanation, I think I would be interested in joining this project. I’ll try and explain the main ideas of what I learned, but there was quite a lot of new information to absorb. Procurement is a department that deals with purchasing items for Fidelity, which can include anything from software and hardware equipment to the desks and chairs used in office. Procurement has to classify these purchases into the appropriate categories to log their spending. The current model is using a rule-based system. However this model is not very flexible, so the project I have the opportunity to get involved with would classify the spending using NLP (Natural Language Processing) using past data of similar spend and possibly enrich the data with third parties to align with industry changes. I’m not totally sure what this means quite yet and some of the terminology is confusing, but I will definitely do some research so that I can come up with more specific questions to ask at the next meeting! I haven’t worked with NLP before this, so I will definitely have a lot of new things to learn and catch up with.
              </p>
              <p>
                Cameron mentioned that this project is in its very early stages of planning, so on the bright side, this means that I might not have as much catching up to do in regard to this project before I get involved. I’m not quite sure who exactly I would be working with, but since I am new to NLP, I would love to have some guidance or specific people I can reach out to with NLP questions. I think this would make the learning process a lot more comfortable and allow me to make more connections. :) Tomorrow I will meet with Kiran and Rajiv to update them on what I talked to Cameron about.
              </p>
              <p>
                This afternoon, I also met with my FYPN mentor, Nancy! We talked for about half an hour mostly about non-work related things, which was a nice break. I was added into a group chat with two other interns who are Nancy’s mentees, Anushka and Benjamin. It was nice to be able to connect with other interns and hear about the experiences of someone newer to Fidelity. I look forward to talking to them more throughout the next couple weeks.
              </p>
              <p>
                Tomorrow is the last day of training! I’m looking forward to getting started on projects and learning as well as connecting with other interns.
              </p>
            </div>
          </div>

          <div id= "June-10-2020-FI">
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 10, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Wednesday</p>
                </div>
                <div class="post-title">
                    <p>Diversifying Connections</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  I started off my morning by joining the APT Scrum meeting. I got to meet the Accounting Dev Team as well as some of the India team. As mentioned yesterday, the Scrum call was a daily status call where the team updates each other on the progress they are making and brings up any problems that they are facing. Specifically, I got to hear from Ramya, the Scrum Master for APT. I got a rough idea of the workflow within the team, but to be completely honest, I had no idea what was going on in terms of the projects that were being discussed. It was a bit intimidating to have so many new concepts swirling around, but on the bright side, this means that I’ll be able to learn a lot of new things!
                </p>
                <p>
                  After the Scrum meeting was the start of training for the day. The majority of training today was about ERGs, which are Employee Resource Groups. We got to hear from the heads of many groups such as Fidelity Pride, AERG (Asian Employee Resource Group), FiVe (Fidelity Veteran Employees), WLG (Women’s Leadership Group), Fidelity Enable, and WITSIG (Women in Technology Special Interest Group). This webinar was quite long, but it was a good way to hear the insights from Fidelity members across many different business groups. After the session I signed up to join AERG, WLG, and WITSIG. I’m looking forward to getting involved and meeting new people from different fields via these groups. :)
                </p>
                <p>
                  Later we had a shorter webinar from Fidelity Cares, which told us about how Fidelity is involved in local communities. As part of the webinar, we participated in a project where we recorded ourselves reading children's books to be sent to local Boys and Girls Clubs across the country.
                </p>
                <p>
                  In the afternoon, I met with Rajiv to talk about his experience at Fidelity as well as to learn more about what happened in the Scrum meeting from the morning. I got to hear about Rajiv’s journey from being an international student studying electrical engineering to getting involved in databases via Oracle and finally working at Fidelity. I also learned a lot about the Waterfall and Agile methodologies. From what I understand, the Waterfall method includes a lot of planning and iterative testing before developments are rolled out. On the other hand, the Agile method includes more frequent deployments based on input from the user and follows the ideology of “pacing over perfection.” Rajiv explained to me that APT uses Agile, with Scrum meetings as a way to check up on the individual members of the team and progress they are making or the problems they are facing. This definitely cleared up a lot of what I was wondering about the workflow and team dynamics at a high/conceptual level, but there is plenty more for me to learn about the process and dynamics of the team. Perhaps I will read up on Agile and Scrum in my free time this week!
                </p>
                <p>
                  Lastly, Rajiv asked me to set up a meeting with Cameron from Procurement Business Analytics. I sent a Zoom invitation to him for 3pm EST tomorrow, where I will be meeting with him as well as Daniel. This meeting is just for me to introduce myself, since it seems like I may be working with them during my internship, as well as get an idea of what their team is working on.
                </p>
                <p>
                  Looking forward to more training and meeting new people tomorrow!
                </p>
            </div>
          </div>

          <div id= "June-09-2020-FI">            
            <div class="post-header">
                <div class="post-date">
                    <p><strong>JUNE 9, 2020</strong></p>
                </div>
                <div class="post-dow">
                    <p>Tuesday</p>
                </div>
                <div class="post-title">
                    <p>Getting Used To It All</p>
                </div>
            </div>
            <div class="post-body">
                <p>
                  Today was pretty similar to yesterday in terms of having mostly webinar training and getting to know the team that I will be working with this summer a bit better. I think I am getting more comfortable with the platforms that Fidelity uses to communicate across the firm, but there is still quite a lot to get used to over the next week. I signed up to be on Digital Champions on Yammer and posted an introduction, which I hope will help me connect me with other interns this summer.
                </p>
                <p>
                  My morning started with a few webinars. We had a brief overview of Fidelity’s history, structure, and financial services. I thought this was a good way to contextualize the work that we will be doing in the upcoming weeks. Some of the terms mentioned were familiar to me from the Econ courses I’ve taken, but there was plenty of information that was very new to me! The next two webinars were about the technology tools that Fidelity uses. We learned about the different roles of Yammer, Microsoft Teams, Skype, Fidelity Central, Workday, Outlook, and Zoom. While this helped me understand the tools, I am still a bit overwhelmed with the amount of locations to check information on. I think I will become more familiar with this software as I continue to use it.
                </p>
                <p>
                  Later in the afternoon, I got to talk to my manager, Rajiv, and meet Kiran, who is in charge of procurement. I think that I will probably be working closely with Kiran’s team since they work primarily in Python, which is one of my strongest languages. It was nice to talk to Rajiv and Kiran and hear about their experiences at Fidelity. Based on what I’ve heard Fidelity seems to have a flexible and balanced work environment!. I will also be attending tomorrow morning’s daily scrum meeting, just to listen in and meet more of the team. :) I look forward to hearing about what my mentors/coworkers have been working on and getting to work alongside them and learn skills from them throughout the internship.
                </p>
                <p>
                  Tomorrow’s training will likely include more webinars and getting familiar with Fidelity’s technology and culture. I’ll try and keep active on Yammer and engage with the team I will be working with, even though we are virtual!
                </p>
            </div>
          </div>

            <div id= "June-08-2020-FI">
                <div class="post-header">
                    <div class="post-date">
                        <p><strong>JUNE 8, 2020</strong></p>
                    </div>
                    <div class="post-dow">
                        <p>Monday</p>
                    </div>
                    <div class="post-title">
                        <p>First Day As A Fidtern!</p>
                    </div>
                </div>
                <div class="post-body">
                    <p>
                      Today was my first day as an intern! This week will primarily be training via online webinars and some meetings with my manager, but I am excited to start learning more about Fidelity and the role that I can play within the firm.
                    </p>
                    <p>
                      I started the morning off by setting up my work laptop. I received two laptops and I am not sure if this was intentional and I will be using both or if this was a mistake. I have reached out to the University Talent team to ask about this issue. I then spent about 2 hours going through my Fidelity email’s inbox and getting acquainted with the different platforms that the firm uses, such as Yammer, Microsoft Teams, Zoom, etc. I found it interesting that Fidelity uses so many different platforms. I am still a bit overwhelmed with trying to keep up with all the platforms, but I anticipate that there is a high learning curve and I will get used to using all these platforms to connect with my new co-workers! :)
                    </p>
                    <p>
                      At 10am we moved onto the webinars. Today’s webinars included a welcome webinar which welcomed all interns to the firm, a Cyber Safety webinar which educated interns about how to protect ourselves and Fidelity from cyberattacks, and a Intentional Connections webinar which addressed how to create meaningful personal relationships while working remotely. I found these webinars pretty informative and I especially enjoyed the Intentional Connections webinar, since I find it a bit more difficult to communicate with people virtually instead of in-person. I am looking forward to more useful information via webinar throughout the week!
                    </p>
                    <p>
                      I was also able to get in contact with my manager (Rajiv) this morning. He introduced me to another member of the team and discussed what I might expect from the internship. It seems that I will be on the Oracle team. Rajiv mentioned that they work closely together with the procurement team, so my role may include being a liaison between the teams. He specifically mentioned that I might be doing some documentation and working with Python and Java during my internship. I am looking forward to learning more about Agile and development releases, since Rajiv mentioned these two areas which I don’t have much previous experience with. This seems very different from my CS experience last summer and I am looking forward to learning a lot of new CS applications through this new experience!
                    </p>
                    <p>
                      Tomorrow holds another full day of webinars and hopefully I can meet more of my fellow interns as well as getting to know the team I will be working with this summer!
                    </p>
                </div>
            </div>
        </div>

        <div class="proj-footer">
            <p>
              This project was for my Summer 2020 remote internship at Fidelity Investments. I worked as a Software Engineering Intern as part of the CTG (Corporate Technology Group) business group, specifically on the FPAIT (Finance Procurement Accounting Information Technology).
              <br>My project was in close partnership with the Business Procurement Team to implement NLP into their Spend classification process so that it is more flexible and requires less manual upkeep. This was my first exposure to Machine Learning and NLP and there was definitely a lot of struggle with trial and error throughout the process.
              <br>By the end of the summer I developed a 97% accurate model that is being taken forward to productionalization.
              
            </p>
        </div>
    </div>

    <!-- JavaScript for Navigation Bar-->
    <script>
      function openNav() {
        document.getElementById("mySidebar").style.width = "250px";
        document.getElementById("main").style.marginLeft = "250px";
      }
      
      function closeNav() {
        document.getElementById("mySidebar").style.width = "0";
        document.getElementById("main").style.marginLeft= "0";
      }

      window.onscroll = function() {myFunction()};
      var header = document.getElementById("myHeader");
      var sticky = header.offsetTop;
      function myFunction() {
          if (window.pageYOffset > sticky) {
              header.classList.add("sticky");
          } else {
            header.classList.remove("sticky");
          }
      }
    </script>

    <!-- Optional JavaScript for Bootstrap -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS-->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>

  </body>
</html>